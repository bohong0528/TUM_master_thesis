{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:19:43.963037300Z",
     "start_time": "2024-01-05T00:19:43.928475600Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, make_scorer, max_error, explained_variance_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, RandomizedSearchCV, StratifiedKFold, cross_validate, train_test_split\n",
    "from scipy.stats import expon, reciprocal, uniform\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, DotProduct, ExpSineSquared, RationalQuadratic\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mango import Tuner, scheduler\n",
    "import xgboost as xgb\n",
    "from skopt  import BayesSearchCV \n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:08:59.821733Z",
     "start_time": "2024-01-05T00:08:33.233652700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file_list, df_activities, df_links_network):\n",
    "    data_frames = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data['link_counts'], dict):\n",
    "                data['link_counts'] = data['link_counts'].values()\n",
    "            df_links = pd.DataFrame({\n",
    "                'link_id': data['links_id'],\n",
    "                'link_from': data['link_from'],\n",
    "                'link_to': data['link_to'],\n",
    "                'link_length': data['link_length'],\n",
    "                'link_freespeed': data['link_freespeed'],\n",
    "                'link_capacity': data['link_capacity'],\n",
    "                'link_permlanes': data['link_permlanes'],\n",
    "                'link_counts': data['link_counts']\n",
    "            })\n",
    "            df_nodes = pd.DataFrame({\n",
    "                'node_id': data['nodes_id'],\n",
    "                'node_x': data['nodes_x'],\n",
    "                'node_y': data['nodes_y']\n",
    "            })\n",
    "            df_od_pairs = pd.DataFrame(data['o_d_pairs'], columns=['origin', 'destination'])\n",
    "            \n",
    "            df_work = pd.DataFrame({\n",
    "                        'work_x': data['work_x'],\n",
    "                        'work_y': data['work_y'],\n",
    "                        'go_to_work': data['go_to_work']\n",
    "            })\n",
    "            df_home = pd.DataFrame({\n",
    "                'home_x': data['home_x'],\n",
    "                'home_y': data['home_y'],\n",
    "                'go_to_home': data['go_to_home']\n",
    "            })\n",
    "            \n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_from', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'start_node_x', 'node_y': 'start_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_to', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'end_node_x', 'node_y': 'end_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True) \n",
    "            \n",
    "            origin_counts = df_od_pairs['origin'].value_counts()\n",
    "            df_origin_counts = origin_counts.reset_index()\n",
    "            df_origin_counts.columns = ['origin', 'start_count']\n",
    "            destination_counts = df_od_pairs['destination'].value_counts()\n",
    "            df_destination_counts = destination_counts.reset_index()\n",
    "            df_destination_counts.columns = ['destination', 'end_count']\n",
    "            df_links = df_links.merge(df_origin_counts, how='left', left_on='link_from', right_on='origin')\n",
    "            df_links.drop('origin', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_destination_counts, how='left', left_on='link_to', right_on='destination')\n",
    "            df_links.drop('destination', axis=1, inplace=True)\n",
    "            df_links[['start_count','end_count']] = df_links[['start_count','end_count']].fillna(-1)\n",
    "            \n",
    "            # Calculate time of go_to_work and go_to_sum\n",
    "            df_act_work = df_activities[df_activities['activity_type_main']=='work'].drop(['end_time'], axis=1)\n",
    "            df_act_work = df_act_work.merge(df_work, how='left', left_on=['x','y'], right_on=['work_x','work_y'])\n",
    "            df_act_work.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_work_agg = df_act_work.groupby(by=\"link\")['go_to_work'].sum().reset_index(drop=False)\n",
    "            df_act_home = df_activities[df_activities['activity_type_main']=='home'].drop(['end_time'], axis=1)\n",
    "            df_act_home = df_act_home.merge(df_home, how='left', left_on=['x','y'], right_on=['home_x','home_y'])\n",
    "            df_act_home.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_home_agg = df_act_home.groupby(by=\"link\")['go_to_home'].sum().reset_index(drop=False)\n",
    "            df_act_agg = df_act_home_agg.merge(df_act_work_agg, how='outer', on='link')\n",
    "            df_act_agg.fillna(0, inplace=True)\n",
    "            df_act_agg['go_to_sum'] = df_act_agg['go_to_home'] + df_act_agg['go_to_work']\n",
    "\n",
    "            df_rushhr = df_activities[df_activities['end_time']!=-1]\n",
    "            df_rushhr.loc[:, 'rush_hour'] = 0\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('08:00:00'), pd.to_timedelta('10:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('16:00:00'), pd.to_timedelta('19:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
    "            df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
    "            \n",
    "            df_maxduragg = df_activities[df_activities['max_dur']!=-1].groupby(by='link')['max_dur'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_activities['cemdapStopDuration_s'] = df_activities['cemdapStopDuration_s'].astype(float)\n",
    "            df_cemagg = df_activities[df_activities['cemdapStopDuration_s']!=-1].groupby(by='link')['cemdapStopDuration_s'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_temp = df_links.merge(df_links_network, how='left', on=['start_node_x','start_node_y','end_node_x','end_node_y'])\n",
    "            df_temp = df_temp[['link_id_x','link_from','link_to','link_id_y','from', 'to', 'type']]\n",
    "            df_temp = df_temp.merge(df_act_agg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_rushhragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_maxduragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_cemagg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.fillna({'cemdapStopDuration_s':-1, 'max_dur':-1, 'rush_hour': -1, 'go_to_sum': -1}, inplace=True)\n",
    "            df_temp = df_temp[['link_id_x', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s', 'type']]\n",
    "            \n",
    "            df_links = df_links.merge(df_temp, how='left', left_on='link_id', right_on='link_id_x')\n",
    "            df_links.drop('link_id_x', axis=1, inplace=True)\n",
    "            df_links['length_per_capacity_ratio'] = df_links['link_length'] / df_links['link_capacity']\n",
    "            df_links['speed_capacity_ratio'] = df_links['link_freespeed'] / df_links['link_capacity']\n",
    "            df_links['length_times_lanes'] = df_links['link_length'] * df_links['link_permlanes']\n",
    "            df_links['speed_times_capacity'] = df_links['link_freespeed'] * df_links['link_capacity']\n",
    "            df_links['length_times'] = df_links['link_length'] / df_links['link_freespeed']\n",
    "            df_links['capacity_divided_by_lanes'] = df_links['link_capacity'] / df_links['link_permlanes']\n",
    "\n",
    "        data_frames.append(df_links)\n",
    "    return pd.concat(data_frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_files = ['s-0.json', 's-1.json', 's-2.json', 's-3.json', 's-4.json','s-5.json', 's-6.json', 's-7.json', 's-8.json', 's-9.json'] \n",
    "test_files = ['s-15.json', 's-16.json', 's-17.json', 's-18.json','s-19.json']\n",
    "validate_files = ['s-10.json', 's-11.json', 's-12.json', 's-13.json','s-14.json']\n",
    "train_files = ['Data/cutoutWorlds/Train/po-1_pn-1.0_sn-1/' + i for i in train_files]\n",
    "test_files = ['Data/cutoutWorlds/Test/po-1_pn-1.0_sn-1/' + j for j in test_files]\n",
    "validate_files = ['Data/cutoutWorlds/Validate/po-1_pn-1.0_sn-1/' + k for k in validate_files]\n",
    "df_activities = pd.read_pickle(\"Data/cutoutWorlds/Train/po-1_pn-1.0_sn-1/df_activities.pkl\")\n",
    "df_links_network = pd.read_pickle(\"Data/cutoutWorlds/Train/po-1_pn-1.0_sn-1/df_links_network.pkl\")\n",
    "train_data = load_data(train_files, df_activities, df_links_network)\n",
    "\n",
    "test_data = load_data(test_files, df_activities, df_links_network)\n",
    "validate_data = load_data(validate_files, df_activities, df_links_network)\n",
    "Big_train_data = pd.concat([train_data, validate_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:31.053189200Z",
     "start_time": "2024-01-05T00:25:30.986858300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['link_id', 'link_from', 'link_to', 'start_node_x', 'start_node_y', 'end_node_x', 'end_node_y',\n",
    "                      'link_length', 'link_freespeed', 'link_capacity', 'link_permlanes', 'start_count', 'end_count',\n",
    "                      'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s', 'length_per_capacity_ratio', 'speed_capacity_ratio',\n",
    "                      'length_times_lanes', 'speed_times_capacity', 'length_times', 'capacity_divided_by_lanes'\n",
    "                     ]\n",
    "category_feature = ['type']\n",
    "X_t = Big_train_data.drop(columns=['link_counts'])\n",
    "y_t = Big_train_data['link_counts']\n",
    "X_te = test_data.drop(columns=['link_counts'])\n",
    "y_te = test_data['link_counts']\n",
    "scaler = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ct = ColumnTransformer(\n",
    "     [(\"num_preprocess\", scaler, numerical_features),\n",
    "      (\"text_preprocess\", ohe, category_feature)], remainder='passthrough').set_output(transform=\"pandas\")\n",
    "X_t = ct.fit_transform(X_t)\n",
    "X_te = ct.fit_transform(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'learning_rate': np.arange(0.01, 1.0, 0.01),\n",
    "    'n_estimators': np.arange(50, 2001, 50),\n",
    "    'max_depth': np.arange(1, 200),\n",
    "    'num_leaves': np.arange(2, 200),\n",
    "    'min_child_samples': np.arange(1, 20),\n",
    "    'subsample': np.arange(0.1, 1.0, 0.1),\n",
    "    'colsample_bytree': np.arange(0.1, 1.0, 0.1),\n",
    "    'reg_alpha': np.arange(0, 100),\n",
    "    'reg_lambda': np.arange(0, 20, 0.01),\n",
    "}\n",
    "\n",
    "# Define the LGBMRegressor model\n",
    "lgbm_model = lgb.LGBMRegressor(random_state=101)\n",
    "\n",
    "# Create a Bayesian optimization object\n",
    "opt = BayesSearchCV(\n",
    "    lgbm_model,\n",
    "    param_space,\n",
    "    n_iter=100,  # Adjust the number of iterations based on your computational resources\n",
    "    cv=3,  # Adjust the number of cross-validation folds\n",
    "    scoring='neg_mean_absolute_error',  # Use a suitable regression metric\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_t, y_t)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = opt.best_params_\n",
    "print(opt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "final_model = lgb.LGBMRegressor(**best_params, random_state=101)\n",
    "final_model.fit(X_t, y_t)\n",
    "\n",
    "print(\"With LGB Pred\")\n",
    "y_t_pred = final_model.predict(X_t)\n",
    "print(mean_absolute_error(y_t, y_t_pred))\n",
    "\n",
    "y_te_pred = final_model.predict(X_te)\n",
    "print(mean_absolute_error(y_te, y_te_pred))\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "X_t_leaves = onehot.fit_transform(final_model.predict(X_t, pred_leaf=True))\n",
    "xgb_lr = LogisticRegression()\n",
    "xgb_lr.fit(X_t_leaves, y_t)\n",
    "\n",
    "print(\"With LGB + LR Pred\")\n",
    "X_t_leaves = onehot.transform(final_model.predict(X_t, pred_leaf=True))\n",
    "y_t_pred_xgb_lr = xgb_lr.predict(X_t_leaves)\n",
    "print(mean_absolute_error(y_t, y_t_pred_xgb_lr))\n",
    "\n",
    "X_te_leaves = onehot.transform(final_model.predict(X_te, pred_leaf=True))\n",
    "y_te_pred_xgb_lr = xgb_lr.predict(X_te_leaves)\n",
    "print(mean_absolute_error(y_te, y_te_pred_xgb_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'learning_rate': np.arange(0.01, 1.0, 0.01),\n",
    "    'n_estimators': np.arange(50, 2001, 50),\n",
    "    'max_depth': np.arange(1, 20),\n",
    "    'max_leaves': np.arange(2, 50),\n",
    "    'max_bin': np.arange(2, 50),\n",
    "    'gamma': np.arange(1, 20),\n",
    "    'min_child_weight': np.arange(0, 20),\n",
    "    'subsample': np.arange(0.1, 1.0, 0.1),\n",
    "    'colsample_bytree': np.arange(0.1, 1.0, 0.1),\n",
    "    'reg_alpha': np.arange(0, 100),\n",
    "    'reg_lambda': np.arange(0, 10, 0.01),\n",
    "}\n",
    "\n",
    "# Define the LGBMRegressor model\n",
    "lgbm_model = xgb.XGBRegressor(random_state=101)\n",
    "\n",
    "# Create a Bayesian optimization object\n",
    "opt = BayesSearchCV(\n",
    "    lgbm_model,\n",
    "    param_space,\n",
    "    n_iter=100,  # Adjust the number of iterations based on your computational resources\n",
    "    cv=3,  # Adjust the number of cross-validation folds\n",
    "    scoring='neg_mean_absolute_error',  # Use a suitable regression metric\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_t, y_t)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = opt.best_params_\n",
    "print(opt.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "final_model = xgb.XGBRegressor(**best_params, random_state=101)\n",
    "final_model.fit(X_t, y_t)\n",
    "\n",
    "print(\"With XGB Pred\")\n",
    "y_t_pred = final_model.predict(X_t)\n",
    "print(mean_absolute_error(y_t, y_t_pred))\n",
    "\n",
    "y_te_pred = final_model.predict(X_te)\n",
    "print(mean_absolute_error(y_te, y_te_pred))\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "X_t_leaves = onehot.fit_transform(final_model.apply(X_t))\n",
    "xgb_lr = LogisticRegression()\n",
    "xgb_lr.fit(X_t_leaves, y_t)\n",
    "\n",
    "print(\"With XGB + LR Pred\")\n",
    "X_t_leaves = onehot.transform(final_model.apply(X_t))\n",
    "y_t_pred_xgb_lr = xgb_lr.predict(X_t_leaves)\n",
    "print(mean_absolute_error(y_t, y_t_pred_xgb_lr))\n",
    "\n",
    "X_te_leaves = onehot.transform(final_model.apply(X_te))\n",
    "y_te_pred_xgb_lr = xgb_lr.predict(X_te_leaves)\n",
    "print(mean_absolute_error(y_te, y_te_pred_xgb_lr))\n",
    "\n",
    "\n",
    "# # Make predictions on the validation set\n",
    "# y_pred = final_model.predict(X_te)\n",
    "\n",
    "# # Evaluate the model on the validation set\n",
    "# mae = mean_absolute_error(y_te, y_pred)\n",
    "# print(f'Mean Absolute Error on Validation Set: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Categorical\n",
    "param_space = {\n",
    "    'n_neighbors': np.arange(1, 50),\n",
    "    'weights': Categorical(['uniform', 'distance']),\n",
    "    'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "# Create a Bayesian optimization object\n",
    "opt = BayesSearchCV(\n",
    "    knn,\n",
    "    param_space,\n",
    "    n_iter=100,  # Adjust the number of iterations based on your computational resources\n",
    "    cv=3,  # Adjust the number of cross-validation folds\n",
    "    scoring='neg_mean_absolute_error',  # Use a suitable regression metric\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_t, y_t)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = opt.best_params_\n",
    "print(opt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "# final_model = KNeighborsRegressor(**best_params)\n",
    "final_model = KNeighborsRegressor(algorithm='kd_tree', n_neighbors=49, weights='distance')\n",
    "final_model.fit(X_t, y_t)\n",
    "\n",
    "print(\"With KNN Pred\")\n",
    "y_t_pred = final_model.predict(X_t)\n",
    "print(mean_absolute_error(y_t, y_t_pred))\n",
    "\n",
    "y_te_pred = final_model.predict(X_te)\n",
    "print(mean_absolute_error(y_te, y_te_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T15:58:29.829296Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'C': np.logspace(-3, 2, 6),\n",
    "    'gamma': Categorical(['scale', 'auto']),  # Including specific gamma values\n",
    "    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),  # Focusing on RBF kernel\n",
    "    'epsilon': np.arange(0.01, 1, 0.01),  # Epsilon in the epsilon-SVR model\n",
    "}\n",
    "# Define the LGBMRegressor model\n",
    "svr = SVR()\n",
    "\n",
    "# Create a Bayesian optimization object\n",
    "opt = BayesSearchCV(\n",
    "    svr,\n",
    "    param_space,\n",
    "    n_iter=100,  # Adjust the number of iterations based on your computational resources\n",
    "    cv=3,  # Adjust the number of cross-validation folds\n",
    "    scoring='neg_mean_absolute_error',  # Use a suitable regression metric\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_t, y_t)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = opt.best_params_\n",
    "print(opt.best_estimator_)\n",
    "\n",
    "final_model = SVR(**best_params)\n",
    "final_model.fit(X_t, y_t)\n",
    "\n",
    "print(\"With SVR Pred\")\n",
    "y_t_pred = final_model.predict(X_t)\n",
    "print(mean_absolute_error(y_t, y_t_pred))\n",
    "\n",
    "y_te_pred = final_model.predict(X_te)\n",
    "print(mean_absolute_error(y_te, y_te_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T01:20:56.486270700Z",
     "start_time": "2023-12-31T01:19:49.061059700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_space =  {\n",
    "    'max_features': Categorical(['sqrt', 'log2']),\n",
    "    'n_estimators': np.arange(50, 2001, 50),\n",
    "    'bootstrap': Categorical([True, False]),\n",
    "    'max_depth': np.arange(1, 20),\n",
    "    'min_samples_leaf': np.arange(1, 20),\n",
    "    'criterion': Categorical(['squared_error', 'absolute_error', 'friedman_mse', 'poisson'])\n",
    "}\n",
    "# Define the LGBMRegressor model\n",
    "rf_model = RandomForestRegressor(random_state=101)\n",
    "\n",
    "# Create a Bayesian optimization object\n",
    "opt = BayesSearchCV(\n",
    "    rf_model,\n",
    "    param_space,\n",
    "    n_iter=100,  # Adjust the number of iterations based on your computational resources\n",
    "    cv=3,  # Adjust the number of cross-validation folds\n",
    "    scoring='neg_mean_absolute_error',  # Use a suitable regression metric\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_t, y_t)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = opt.best_params_\n",
    "print(opt.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "final_model = RandomForestRegressor(**best_params, random_state=101)\n",
    "final_model.fit(X_t, y_t)\n",
    "\n",
    "print(\"With RF Pred\")\n",
    "y_t_pred = final_model.predict(X_t)\n",
    "print(mean_absolute_error(y_t, y_t_pred))\n",
    "\n",
    "y_te_pred = final_model.predict(X_te)\n",
    "print(mean_absolute_error(y_te, y_te_pred))\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "X_t_leaves = onehot.fit_transform(final_model.apply(X_t))\n",
    "xgb_lr = LogisticRegression()\n",
    "xgb_lr.fit(X_t_leaves, y_t)\n",
    "\n",
    "print(\"With XGB + LR Pred\")\n",
    "X_t_leaves = onehot.transform(final_model.apply(X_t))\n",
    "y_t_pred_xgb_lr = xgb_lr.predict(X_t_leaves)\n",
    "print(mean_absolute_error(y_t, y_t_pred_xgb_lr))\n",
    "\n",
    "X_te_leaves = onehot.transform(final_model.apply(X_te))\n",
    "y_te_pred_xgb_lr = xgb_lr.predict(X_te_leaves)\n",
    "print(mean_absolute_error(y_te, y_te_pred_xgb_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T14:55:59.094098400Z",
     "start_time": "2023-12-31T14:48:54.215646500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'learning_rate': np.arange(0.01, 1.0, 0.01),\n",
    "    'n_estimators': np.arange(50, 2001, 50),\n",
    "    'max_depth': np.arange(1, 200),\n",
    "    'min_samples_split': np.arange(2, 11, 1),\n",
    "    'min_samples_leaf': np.arange(1, 10),\n",
    "    'subsample': np.arange(0.1, 1.0, 0.1),\n",
    "}\n",
    "# Define the LGBMRegressor model\n",
    "gb_model = GradientBoostingRegressor(random_state=101)\n",
    "\n",
    "# Create a Bayesian optimization object\n",
    "opt = BayesSearchCV(\n",
    "    gb_model,\n",
    "    param_space,\n",
    "    n_iter=100,  # Adjust the number of iterations based on your computational resources\n",
    "    cv=3,  # Adjust the number of cross-validation folds\n",
    "    scoring='neg_mean_absolute_error',  # Use a suitable regression metric\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_t, y_t)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = opt.best_params_\n",
    "print(opt.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = GradientBoostingRegressor(**best_params, random_state=101)\n",
    "final_model.fit(X_t, y_t)\n",
    "\n",
    "print(\"With GB Pred\")\n",
    "y_t_pred = final_model.predict(X_t)\n",
    "print(mean_absolute_error(y_t, y_t_pred))\n",
    "\n",
    "y_te_pred = final_model.predict(X_te)\n",
    "print(mean_absolute_error(y_te, y_te_pred))\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "X_t_leaves = onehot.fit_transform(final_model.apply(X_t))\n",
    "xgb_lr = LogisticRegression()\n",
    "xgb_lr.fit(X_t_leaves, y_t)\n",
    "\n",
    "print(\"With XGB + LR Pred\")\n",
    "X_t_leaves = onehot.transform(final_model.apply(X_t))\n",
    "y_t_pred_xgb_lr = xgb_lr.predict(X_t_leaves)\n",
    "print(mean_absolute_error(y_t, y_t_pred_xgb_lr))\n",
    "\n",
    "X_te_leaves = onehot.transform(final_model.apply(X_te))\n",
    "y_te_pred_xgb_lr = xgb_lr.predict(X_te_leaves)\n",
    "print(mean_absolute_error(y_te, y_te_pred_xgb_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randomstate(model):\n",
    "    current_params = model.get_params()\n",
    "\n",
    "    # Update the random_state if it exists, otherwise add it to the parameters\n",
    "    current_params['random_state'] = 101\n",
    "\n",
    "    # Set the modified parameters back to the model\n",
    "    model.set_params(**current_params)\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "models = {\n",
    "    # 'Linear Regression': LinearRegression(),\n",
    "    # 'Lasso': LassoCV(cv=kf, random_state=42, max_iter=200000),\n",
    "    # 'Logistic': LogisticRegression(),\n",
    "    # 'KNN': pd.read_pickle(\"result_KNN.pkl\")['estimator'],\n",
    "    'XGB': set_randomstate(pd.read_pickle(\"result_XGB.pkl\")['estimator']),\n",
    "    'LGBM': set_randomstate(pd.read_pickle(\"result_LGBM.pkl\")['estimator']),\n",
    "    # 'Ridge': RidgeCV(cv=kf),\n",
    "    # 'SVR': pd.read_pickle(\"result_SVR.pkl\")['estimator'],\n",
    "    # 'Random Forest': RandomForestRegressor(bootstrap=False, max_depth=15, max_features=0.7,\n",
    "    #                   min_samples_leaf=9, n_estimators=200, random_state=101),\n",
    "    # 'Gradient Boosting': GradientBoostingRegressor(learning_rate=0.01, max_depth=14, min_samples_leaf=3,\n",
    "    #                       min_samples_split=4, n_estimators=950, random_state=101, subsample=0.8),\n",
    "    # 'Artificial Neural Network': MLPRegressor(activation='logistic', alpha=0.01, hidden_layer_sizes=(50, 50),\n",
    "    #          max_iter=4000, random_state=101),\n",
    "    # 'Gaussian Process Regression': GaussianProcessRegressor(0.1 ** 2 * RBF(length_scale=0.1) + WhiteKernel(noise_level=0.1 ** 2, noise_level_bounds=(1e-5, 1e5)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB done\n",
      "7.0298131993241295 240.9921619955634 35.576016380838674\n",
      "LGBM done\n",
      "5.845367245957642 189.88326156811485 35.87735422572694\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate models\n",
    "def evaluate_models(models, X_train, y_train):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        scoring=['neg_mean_absolute_error','neg_mean_squared_error']\n",
    "        # Define the cross-validation strategy (e.g., 5-fold cross-validation)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "        # Perform k-fold cross-validation and calculate MSE and MAE\n",
    "        scores = cross_validate(model, X_train, y_train, cv=kf, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "        mean_mae = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mean_mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "        std_mse = scores['test_neg_mean_squared_error'].std()\n",
    "\n",
    "        print(name + \" done\")\n",
    "        print(mean_mae, mean_mse, std_mse)\n",
    "        results[name] = {'MAE': mean_mae, 'MSE': mean_mse, 'MSE_std': std_mse}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train and evaluate\n",
    "results = evaluate_models(models, X_t, y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB done\n",
      "7.0298131993241295 240.9921619955634 35.576016380838674\n",
      "13.623230754027675 634.8837219925555\n",
      "---------------\n",
      "5.743913693100155 135.3866896268765 17.279465065358977\n",
      "15.165224131249193 1014.5255134995479\n",
      "LGBM done\n",
      "5.845367245957642 189.88326156811485 35.87735422572694\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4546\n",
      "[LightGBM] [Info] Number of data points in the train set: 25127, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 19.772874\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "12.73314033705219 467.6134807708623\n",
      "---------------\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m         y_te_pred_xgb_lr \u001b[38;5;241m=\u001b[39m xgb_lr\u001b[38;5;241m.\u001b[39mpredict(X_te_leaves)\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28mprint\u001b[39m(mean_absolute_error(y_test, y_te_pred_xgb_lr), mean_squared_error(y_test, y_te_pred_xgb_lr))\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmodel_lr_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_te\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 36\u001b[0m, in \u001b[0;36mmodel_lr_evaluation\u001b[1;34m(models, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     33\u001b[0m     X_t_leaves \u001b[38;5;241m=\u001b[39m onehot\u001b[38;5;241m.\u001b[39mtransform(final_model\u001b[38;5;241m.\u001b[39mapply(X_train))\n\u001b[0;32m     34\u001b[0m     X_te_leaves \u001b[38;5;241m=\u001b[39m onehot\u001b[38;5;241m.\u001b[39mtransform(final_model\u001b[38;5;241m.\u001b[39mapply(X_test))\n\u001b[1;32m---> 36\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_t_leaves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m mean_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_neg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     38\u001b[0m mean_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_neg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "def model_lr_evaluation(models, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    scoring=['neg_mean_absolute_error','neg_mean_squared_error']\n",
    "\n",
    "    for name, model in models.items():\n",
    "        final_model = model\n",
    "        \n",
    "        scores = cross_validate(model, X_train, y_train, cv=3, scoring=scoring, n_jobs=-1)\n",
    "        mean_mae = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mean_mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "        std_mse = scores['test_neg_mean_squared_error'].std()\n",
    "        print(name + \" done\")\n",
    "        print(mean_mae, mean_mse, std_mse)\n",
    "        \n",
    "        final_model.fit(X_train, y_train)\n",
    "        y_te_pred = final_model.predict(X_test)\n",
    "        print(mean_absolute_error(y_test, y_te_pred), mean_squared_error(y_test, y_te_pred))\n",
    "        \n",
    "        print(\"---------------\")\n",
    "        \n",
    "        onehot = OneHotEncoder()\n",
    "        if name == 'LGBM':\n",
    "            X_t_leaves = onehot.fit_transform(final_model.predict(X_train, pred_leaf=True))\n",
    "        elif name == 'XGB':\n",
    "            X_t_leaves = onehot.fit_transform(final_model.apply(X_train))\n",
    "        xgb_lr = LogisticRegression()\n",
    "        xgb_lr.fit(X_t_leaves, y_train)\n",
    "\n",
    "        if name == 'LGBM':\n",
    "            X_t_leaves = onehot.transform(final_model.predict(X_train, pred_leaf=True))\n",
    "            X_te_leaves = onehot.transform(final_model.predict(X_test, pred_leaf=True))\n",
    "        elif name == 'XGB':\n",
    "            X_t_leaves = onehot.transform(final_model.apply(X_train))\n",
    "            X_te_leaves = onehot.transform(final_model.apply(X_test))\n",
    "\n",
    "        scores = cross_validate(model, X_t_leaves, y_train, cv=kf, scoring=scoring, n_jobs=-1)\n",
    "        mean_mae = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mean_mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "        std_mse = scores['test_neg_mean_squared_error'].std()\n",
    "        print(mean_mae, mean_mse, std_mse) \n",
    "        \n",
    "        y_te_pred_xgb_lr = xgb_lr.predict(X_te_leaves)\n",
    "        print(mean_absolute_error(y_test, y_te_pred_xgb_lr), mean_squared_error(y_test, y_te_pred_xgb_lr))\n",
    "\n",
    "model_lr_evaluation(models, X_t, y_t, X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_with_test(model, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)      \n",
    "    results = {'MAE': mae, 'MSE': mse}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "result_final_with_test = {}\n",
    "for name, model in models.items():\n",
    "    result_final_with_test[name] = evaluate_models_with_test(model, X_t, y_t, X_te, y_te)\n",
    "\n",
    "result_final_with_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
