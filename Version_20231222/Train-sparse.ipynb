{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:19:43.963037300Z",
     "start_time": "2024-01-05T00:19:43.928475600Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import expon, reciprocal, uniform\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, DotProduct, ExpSineSquared, RationalQuadratic\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:08:59.821733Z",
     "start_time": "2024-01-05T00:08:33.233652700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file_list, df_activities, df_links_network):\n",
    "    data_frames = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data['link_counts'], dict):\n",
    "                data['link_counts'] = data['link_counts'].values()\n",
    "            df_links = pd.DataFrame({\n",
    "                'link_id': data['links_id'],\n",
    "                'link_from': data['link_from'],\n",
    "                'link_to': data['link_to'],\n",
    "                'link_length': data['link_length'],\n",
    "                'link_freespeed': data['link_freespeed'],\n",
    "                'link_capacity': data['link_capacity'],\n",
    "                'link_permlanes': data['link_permlanes'],\n",
    "                'link_counts': data['link_counts']\n",
    "            })\n",
    "            df_nodes = pd.DataFrame({\n",
    "                'node_id': data['nodes_id'],\n",
    "                'node_x': data['nodes_x'],\n",
    "                'node_y': data['nodes_y']\n",
    "            })\n",
    "            df_od_pairs = pd.DataFrame(data['o_d_pairs'], columns=['origin', 'destination'])\n",
    "            \n",
    "            df_work = pd.DataFrame({\n",
    "                        'work_x': data['work_x'],\n",
    "                        'work_y': data['work_y'],\n",
    "                        'go_to_work': data['go_to_work']\n",
    "            })\n",
    "            df_home = pd.DataFrame({\n",
    "                'home_x': data['home_x'],\n",
    "                'home_y': data['home_y'],\n",
    "                'go_to_home': data['go_to_home']\n",
    "            })\n",
    "            \n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_from', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'start_node_x', 'node_y': 'start_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_to', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'end_node_x', 'node_y': 'end_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True) \n",
    "            \n",
    "            origin_counts = df_od_pairs['origin'].value_counts()\n",
    "            df_origin_counts = origin_counts.reset_index()\n",
    "            df_origin_counts.columns = ['origin', 'start_count']\n",
    "            destination_counts = df_od_pairs['destination'].value_counts()\n",
    "            df_destination_counts = destination_counts.reset_index()\n",
    "            df_destination_counts.columns = ['destination', 'end_count']\n",
    "            df_links = df_links.merge(df_origin_counts, how='left', left_on='link_from', right_on='origin')\n",
    "            df_links.drop('origin', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_destination_counts, how='left', left_on='link_to', right_on='destination')\n",
    "            df_links.drop('destination', axis=1, inplace=True)\n",
    "            df_links[['start_count','end_count']] = df_links[['start_count','end_count']].fillna(-1)\n",
    "            \n",
    "            # Calculate time of go_to_work and go_to_sum\n",
    "            df_act_work = df_activities[df_activities['activity_type_main']=='work'].drop(['end_time'], axis=1)\n",
    "            df_act_work = df_act_work.merge(df_work, how='left', left_on=['x','y'], right_on=['work_x','work_y'])\n",
    "            df_act_work.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_work_agg = df_act_work.groupby(by=\"link\")['go_to_work'].sum().reset_index(drop=False)\n",
    "            df_act_home = df_activities[df_activities['activity_type_main']=='home'].drop(['end_time'], axis=1)\n",
    "            df_act_home = df_act_home.merge(df_home, how='left', left_on=['x','y'], right_on=['home_x','home_y'])\n",
    "            df_act_home.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_home_agg = df_act_home.groupby(by=\"link\")['go_to_home'].sum().reset_index(drop=False)\n",
    "            df_act_agg = df_act_home_agg.merge(df_act_work_agg, how='outer', on='link')\n",
    "            df_act_agg.fillna(0, inplace=True)\n",
    "            df_act_agg['go_to_sum'] = df_act_agg['go_to_home'] + df_act_agg['go_to_work']\n",
    "\n",
    "            df_rushhr = df_activities[df_activities['end_time']!=-1]\n",
    "            df_rushhr.loc[:, 'rush_hour'] = 0\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('08:00:00'), pd.to_timedelta('10:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('16:00:00'), pd.to_timedelta('19:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
    "            df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
    "            \n",
    "            df_maxduragg = df_activities[df_activities['max_dur']!=-1].groupby(by='link')['max_dur'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_activities['cemdapStopDuration_s'] = df_activities['cemdapStopDuration_s'].astype(float)\n",
    "            df_cemagg = df_activities[df_activities['cemdapStopDuration_s']!=-1].groupby(by='link')['cemdapStopDuration_s'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_temp = df_links.merge(df_links_network, how='left', on=['start_node_x','start_node_y','end_node_x','end_node_y'])\n",
    "            df_temp = df_temp[['link_id_x','link_from','link_to','link_id_y','from', 'to', 'type']]\n",
    "            df_temp = df_temp.merge(df_act_agg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_rushhragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_maxduragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_cemagg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.fillna({'cemdapStopDuration_s':-1, 'max_dur':-1, 'rush_hour': -1, 'go_to_sum': -1}, inplace=True)\n",
    "            df_temp = df_temp[['link_id_x', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s', 'type']]\n",
    "            \n",
    "            df_links = df_links.merge(df_temp, how='left', left_on='link_id', right_on='link_id_x')\n",
    "            df_links.drop('link_id_x', axis=1, inplace=True)\n",
    "        data_frames.append(df_links)\n",
    "    return pd.concat(data_frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16456\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n"
     ]
    }
   ],
   "source": [
    "df_train = []\n",
    "for i in range(0, 10):\n",
    "    train_files = f'Data/sparseWorlds/Train/po-1/s-{i}.json'\n",
    "    df_activities = pd.read_pickle(f'Data/sparseWorlds/Train/po-1/df_activities_{i}.pkl')\n",
    "    df_links_network = pd.read_pickle(f'Data/sparseWorlds/Train/po-1/df_links_network_{i}.pkl')\n",
    "    train_data = load_data([train_files], df_activities, df_links_network)\n",
    "    df_train.append(train_data)\n",
    "train_data_all = pd.concat(df_train, ignore_index=True)\n",
    "\n",
    "df_validate = []\n",
    "for i in range(10, 15):\n",
    "    validate_files = f'Data/sparseWorlds/Validate/po-1/s-{i}.json'\n",
    "    df_activities = pd.read_pickle(f'Data/sparseWorlds/Validate/po-1/df_activities_{i}.pkl')\n",
    "    df_links_network = pd.read_pickle(f'Data/sparseWorlds/Validate/po-1/df_links_network_{i}.pkl')\n",
    "    validate_data = load_data([validate_files], df_activities, df_links_network)\n",
    "    df_validate.append(validate_data)\n",
    "validate_data_all = pd.concat(df_validate, ignore_index=True)\n",
    "    \n",
    "df_test = []\n",
    "for i in range(15, 20):\n",
    "    test_files = f'Data/sparseWorlds/Test/po-1/s-{i}.json'\n",
    "    df_activities = pd.read_pickle(f'Data/sparseWorlds/Test/po-1/df_activities_{i}.pkl')\n",
    "    df_links_network = pd.read_pickle(f'Data/sparseWorlds/Test/po-1/df_links_network_{i}.pkl')\n",
    "    test_data = load_data([test_files], df_activities, df_links_network)\n",
    "    df_test.append(test_data)\n",
    "test_data_all = pd.concat(df_test, ignore_index=True)\n",
    "\n",
    "Big_train_data = pd.concat([train_data_all, validate_data_all], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:31.053189200Z",
     "start_time": "2024-01-05T00:25:30.986858300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['link_length', 'link_freespeed', 'link_capacity', 'link_permlanes', 'start_node_x', 'start_node_y', 'end_node_x', 'end_node_y', 'start_count', 'end_count', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s']\n",
    "category_feature = ['type']\n",
    "X_t = Big_train_data.drop(columns=['link_counts'])\n",
    "y_t = Big_train_data['link_counts']\n",
    "X_te = test_data.drop(columns=['link_counts'])\n",
    "y_te = test_data['link_counts']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ct = ColumnTransformer(\n",
    "     [(\"num_preprocess\", scaler, numerical_features),\n",
    "      (\"text_preprocess\", ohe, category_feature)], remainder='passthrough').set_output(transform=\"pandas\")\n",
    "X_t = ct.fit_transform(X_t) \n",
    "X_te = ct.fit_transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:38.793260300Z",
     "start_time": "2024-01-05T00:25:38.746926800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': LassoCV(cv=kf, random_state=42, max_iter=100000),\n",
    "    'Ridge': RidgeCV(cv=kf),\n",
    "    'SVR': SVR(C=0.01, kernel='sigmoid', max_iter=2000),\n",
    "    'Random Forest': RandomForestRegressor(criterion='friedman_mse', max_depth=20,\n",
    "                      min_samples_leaf=2, n_estimators=200, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(max_depth=10, min_samples_leaf=4, random_state=42),\n",
    "    'Artificial Neural Network': MLPRegressor(activation='tanh', alpha=0.001, hidden_layer_sizes=(100, 100),\n",
    "             max_iter=2000, random_state=42),\n",
    "#     'Gaussian Process Regression': GaussianProcessRegressor(kernel=RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0), alpha=0.1, n_restarts_optimizer=3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:31:29.592973900Z",
     "start_time": "2024-01-05T00:28:22.015669500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression selection done\n",
      "Lasso selection done\n",
      "Ridge selection done\n",
      "SVR selection done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest selection done\n",
      "Gradient Boosting selection done\n",
      "Artificial Neural Network selection done\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate models\n",
    "def evaluate_models(models, X_train, y_train):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         mse = mean_squared_error(y_test, y_pred)\n",
    "#         mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "        mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "        # Define the cross-validation strategy (e.g., 5-fold cross-validation)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # Perform k-fold cross-validation and calculate MSE and MAE\n",
    "        mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mse_scorer)\n",
    "        mae_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mae_scorer)\n",
    "\n",
    "        # Display the mean MSE and MAE across folds\n",
    "        mean_mse = -mse_scores.mean()\n",
    "        mean_mae = -mae_scores.mean()\n",
    "        std_mse = mse_scores.std()\n",
    "        # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        # r2 = r2_score(y_test, y_pred)\n",
    "        print(name + \" done\")\n",
    "        \n",
    "        results[name] = {'MAE': mean_mae, 'MSE': mean_mse, 'MSE_std': std_mse}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def feature_select_models(models, X_train, y_train):\n",
    "    mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name not in ['SVR', 'Artificial Neural Network', 'Gaussian Process Regression']:\n",
    "            selector = RFECV(model, step=1, cv=kf, scoring=mse_scorer).fit(X_train, y_train)\n",
    "            print(f'{name} selection done')\n",
    "\n",
    "        else:\n",
    "            # Fit Random Forest to get feature importances\n",
    "            rf = RandomForestRegressor()\n",
    "            rf.fit(X_train, y_train)\n",
    "            # Select features based on importances\n",
    "            selector = RFECV(estimator=rf, step=1, cv=kf, scoring=mse_scorer).fit(X_train, y_train)\n",
    "            print(f'{name} selection done')\n",
    "            \n",
    "        selected_features = X_train.columns[selector.support_]\n",
    "        X_train_reduced = X_train[selected_features] \n",
    "        mse_scores = cross_val_score(model, X_train_reduced, y_train, cv=kf, scoring=mse_scorer)\n",
    "        mse = -mse_scores.mean()\n",
    "        mse_std = mse_scores.std()           \n",
    "        mae_scores = cross_val_score(model, X_train_reduced, y_train, cv=kf, scoring=mae_scorer)\n",
    "        mean_mae = -mae_scores.mean()\n",
    "\n",
    "        results[name] = {'MAE': mean_mae, 'MSE': mse, 'MSE_std': mse_std, 'selected_feature': selected_features}\n",
    "\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Train and evaluate\n",
    "# results = evaluate_models(models, X_t, y_t)\n",
    "\n",
    "results_feature = feature_select_models(models, X_t, y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 4.693113446842107,\n",
       "  'MSE': 55.849006153897605,\n",
       "  'MSE_std': 2.432367097366999},\n",
       " 'Lasso': {'MAE': 4.73523872550065,\n",
       "  'MSE': 56.36714670885806,\n",
       "  'MSE_std': 2.4722245661994404},\n",
       " 'Ridge': {'MAE': 4.692299720318795,\n",
       "  'MSE': 55.84925513445673,\n",
       "  'MSE_std': 2.4336838277175006},\n",
       " 'SVR': {'MAE': 3.796789836594848,\n",
       "  'MSE': 66.91232244253311,\n",
       "  'MSE_std': 3.0398415798701195},\n",
       " 'Random Forest': {'MAE': 3.8049070279424213,\n",
       "  'MSE': 45.3557022895851,\n",
       "  'MSE_std': 1.9916994575650346},\n",
       " 'Gradient Boosting': {'MAE': 4.435219723809254,\n",
       "  'MSE': 51.70751836160465,\n",
       "  'MSE_std': 2.3147557241346983},\n",
       " 'Artificial Neural Network': {'MAE': 5.1972694271238336,\n",
       "  'MSE': 65.93310931246707,\n",
       "  'MSE_std': 16.515316185356948}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before hyperparametertuning\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('result_sparse_after_featureselection(wo gpr).pkl', 'wb') as file:\n",
    "    pickle.dump(results_feature, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 4.693113446842107,\n",
       "  'MSE': 55.849006153897605,\n",
       "  'MSE_std': 2.432367097366999},\n",
       " 'Lasso': {'MAE': 4.73523872550065,\n",
       "  'MSE': 56.36714670885806,\n",
       "  'MSE_std': 2.4722245661994404},\n",
       " 'Ridge': {'MAE': 4.692299720318795,\n",
       "  'MSE': 55.84925513445673,\n",
       "  'MSE_std': 2.4336838277175006},\n",
       " 'SVR': {'MAE': 5.977155856752495,\n",
       "  'MSE': 61.98269569332149,\n",
       "  'MSE_std': 2.0059101781075888},\n",
       " 'Random Forest': {'MAE': 3.7669767167115547,\n",
       "  'MSE': 43.49061871205631,\n",
       "  'MSE_std': 2.233419838225602},\n",
       " 'Gradient Boosting': {'MAE': 3.8769150608008958,\n",
       "  'MSE': 44.29968885637518,\n",
       "  'MSE_std': 2.00551870212844},\n",
       " 'Artificial Neural Network': {'MAE': 4.755552312927051,\n",
       "  'MSE': 57.868662954965124,\n",
       "  'MSE_std': 2.4034977982000765}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after hyperparametertuning\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 4.692953454109057,\n",
       "  'MSE': 55.847603502380174,\n",
       "  'MSE_std': 2.436216250739268,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__go_to_sum', 'num_preprocess__rush_hour',\n",
       "         'num_preprocess__max_dur', 'num_preprocess__cemdapStopDuration_s',\n",
       "         'text_preprocess__type_motorway', 'text_preprocess__type_motorway_link',\n",
       "         'text_preprocess__type_primary', 'text_preprocess__type_primary_link',\n",
       "         'text_preprocess__type_residential', 'text_preprocess__type_secondary',\n",
       "         'text_preprocess__type_secondary_link',\n",
       "         'text_preprocess__type_tertiary', 'text_preprocess__type_trunk',\n",
       "         'text_preprocess__type_unclassified', 'remainder__link_from',\n",
       "         'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'Lasso': {'MAE': 4.722143368234876,\n",
       "  'MSE': 56.29505664393014,\n",
       "  'MSE_std': 2.472412176879856,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__rush_hour', 'num_preprocess__max_dur',\n",
       "         'text_preprocess__type_primary'],\n",
       "        dtype='object')},\n",
       " 'Ridge': {'MAE': 4.69213195010331,\n",
       "  'MSE': 55.84778430670252,\n",
       "  'MSE_std': 2.4374630419924093,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__go_to_sum', 'num_preprocess__rush_hour',\n",
       "         'num_preprocess__max_dur', 'num_preprocess__cemdapStopDuration_s',\n",
       "         'text_preprocess__type_motorway', 'text_preprocess__type_motorway_link',\n",
       "         'text_preprocess__type_primary', 'text_preprocess__type_primary_link',\n",
       "         'text_preprocess__type_residential', 'text_preprocess__type_secondary',\n",
       "         'text_preprocess__type_secondary_link',\n",
       "         'text_preprocess__type_tertiary', 'text_preprocess__type_trunk',\n",
       "         'text_preprocess__type_unclassified', 'remainder__link_from',\n",
       "         'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'SVR': {'MAE': 5.8782451998879575,\n",
       "  'MSE': 61.55525364195482,\n",
       "  'MSE_std': 1.9564222979379748,\n",
       "  'selected_feature': Index(['num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'remainder__link_id', 'remainder__link_from', 'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'Random Forest': {'MAE': 3.676653324841554,\n",
       "  'MSE': 41.9730996902583,\n",
       "  'MSE_std': 2.323435555674916,\n",
       "  'selected_feature': Index(['num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'remainder__link_id', 'remainder__link_from', 'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'Gradient Boosting': {'MAE': 3.8131323816781815,\n",
       "  'MSE': 43.07890610750065,\n",
       "  'MSE_std': 2.6703016857829356,\n",
       "  'selected_feature': Index(['num_preprocess__start_node_x', 'num_preprocess__end_node_y',\n",
       "         'remainder__link_id'],\n",
       "        dtype='object')},\n",
       " 'Artificial Neural Network': {'MAE': 4.781284042483849,\n",
       "  'MSE': 57.98457165764254,\n",
       "  'MSE_std': 2.530863083553044,\n",
       "  'selected_feature': Index(['num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'remainder__link_id', 'remainder__link_from', 'remainder__link_to'],\n",
       "        dtype='object')}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T15:58:29.829296Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "{'C': 0.01, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "SVR(C=0.01, kernel='sigmoid', max_iter=2000)\n",
      "-61.98269569332149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid_svr = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Extended range for the regularization parameter\n",
    "    'gamma': ['scale', 'auto'],  # Including specific gamma values\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Focusing on RBF kernel\n",
    "    'epsilon': [0.01, 0.1, 0.2],  # Epsilon in the epsilon-SVR model\n",
    "}\n",
    "\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search_svr = GridSearchCV(SVR(max_iter=2000), param_grid_svr, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "random_search_svr.fit(X_t, y_t)\n",
    "print(random_search_svr.best_params_)\n",
    "print(random_search_svr.best_estimator_)\n",
    "print(random_search_svr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T01:20:56.486270700Z",
     "start_time": "2023-12-31T01:19:49.061059700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "{'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "RandomForestRegressor(criterion='friedman_mse', max_depth=20,\n",
      "                      min_samples_leaf=2, n_estimators=200, random_state=42)\n",
      "-43.49061871205631\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion':['friedman_mse']\n",
    "}\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "grid_search_rf.fit(X_t, y_t)\n",
    "\n",
    "print(grid_search_rf.best_params_)\n",
    "print(grid_search_rf.best_estimator_)\n",
    "print(grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T14:55:59.094098400Z",
     "start_time": "2023-12-31T14:48:54.215646500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1.0}\n",
      "GradientBoostingRegressor(max_depth=10, min_samples_leaf=4, random_state=42)\n",
      "-44.29968885637518\n"
     ]
    }
   ],
   "source": [
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Varied learning rates for gradient boosting\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'subsample': [0.8, 1.0],  # Fraction of samples to be used for fitting individual base learners\n",
    "}\n",
    "\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_gb = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_gb, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "grid_search_gb.fit(X_t, y_t)\n",
    "print(grid_search_gb.best_params_)\n",
    "print(grid_search_gb.best_estimator_)\n",
    "print(grid_search_gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T19:56:11.590867600Z",
     "start_time": "2024-01-02T19:50:33.301610200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "24 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-5.82118792e+01 -5.79665877e+01 -5.82357920e+01 -5.78565854e+01\n",
      " -5.81625921e+01 -5.80447736e+01 -5.82413961e+01 -5.79468957e+01\n",
      " -5.81437772e+01 -5.80762244e+01 -5.81831456e+01 -5.80742824e+01\n",
      " -5.82824885e+01 -5.77791780e+01 -5.81463353e+01 -5.79847997e+01\n",
      " -5.82806719e+01 -5.77460702e+01 -5.81848427e+01 -5.80918638e+01\n",
      " -5.82175217e+01 -5.80397261e+01 -5.83166101e+01 -5.78763525e+01\n",
      " -5.81439025e+01 -5.79903766e+01 -5.81789134e+01 -5.80426172e+01\n",
      " -5.81539059e+01 -5.80210640e+01 -2.92318202e+51 -6.10980005e+01\n",
      " -5.83212959e+01 -6.47733378e+01             nan -6.73814583e+01\n",
      " -1.29608875e+44 -6.76391330e+01             nan -5.89320609e+01\n",
      " -2.92324943e+51 -6.15059435e+01 -5.83212959e+01 -6.04966308e+01\n",
      "             nan -6.38414659e+01 -1.29608871e+44 -6.61646995e+01\n",
      "             nan -5.84140517e+01 -2.92392352e+51 -7.15964186e+01\n",
      " -5.83212959e+01 -6.03742558e+01             nan -6.36680323e+01\n",
      " -1.29608832e+44 -6.55002561e+01             nan -5.88885502e+01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 100), 'solver': 'adam'}\n",
      "MLPRegressor(activation='tanh', alpha=0.001, hidden_layer_sizes=(100, 100),\n",
      "             max_iter=2000, random_state=42)\n",
      "-57.74607022008577\n"
     ]
    }
   ],
   "source": [
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100), (30, 30, 30)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "}\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_mlp = GridSearchCV(MLPRegressor(max_iter=2000, random_state=42), param_grid_mlp, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "grid_search_mlp.fit(X_t, y_t)\n",
    "print(grid_search_mlp.best_params_)\n",
    "print(grid_search_mlp.best_estimator_)\n",
    "print(grid_search_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T21:55:20.525741600Z",
     "start_time": "2024-01-01T20:54:36.357249300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15896\\1928377076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Initialize GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgrid_search_gpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrid_search_gpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search_gpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m         \u001b[0mcv_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2305\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2307\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    287\u001b[0m                 \u001b[1;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[1;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0."
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, DotProduct\n",
    "import numpy as np\n",
    "param_grid = {\n",
    "    'kernel': [ConstantKernel (1.0, (1e-1, 1e1)) * RBF(1.0, (1e-2, 1e2))],\n",
    "    'alpha': [ 1e-2, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "gpr = GaussianProcessRegressor(copy_X_train=False)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_gpr = RandomizedSearchCV(gpr, param_grid, n_iter=5, cv=0, scoring='neg_mean_squared_error', n_jobs=-1, verbose=10)\n",
    "grid_search_gpr.fit(X_t, y_t)\n",
    "\n",
    "print(grid_search_gpr.best_params_)\n",
    "print(grid_search_gpr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models_with_test(model, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "      \n",
    "    results = {'MAE': mae, 'MSE': mse}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preprocess__link_length</th>\n",
       "      <th>num_preprocess__link_freespeed</th>\n",
       "      <th>num_preprocess__link_capacity</th>\n",
       "      <th>num_preprocess__link_permlanes</th>\n",
       "      <th>num_preprocess__start_node_x</th>\n",
       "      <th>num_preprocess__start_node_y</th>\n",
       "      <th>num_preprocess__end_node_x</th>\n",
       "      <th>num_preprocess__end_node_y</th>\n",
       "      <th>num_preprocess__start_count</th>\n",
       "      <th>num_preprocess__end_count</th>\n",
       "      <th>...</th>\n",
       "      <th>text_preprocess__type_primary_link</th>\n",
       "      <th>text_preprocess__type_residential</th>\n",
       "      <th>text_preprocess__type_secondary</th>\n",
       "      <th>text_preprocess__type_secondary_link</th>\n",
       "      <th>text_preprocess__type_tertiary</th>\n",
       "      <th>text_preprocess__type_unclassified</th>\n",
       "      <th>remainder__link_id</th>\n",
       "      <th>remainder__link_from</th>\n",
       "      <th>remainder__link_to</th>\n",
       "      <th>text_preprocess__type_trunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.719399</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>0.373713</td>\n",
       "      <td>0.546057</td>\n",
       "      <td>-0.513968</td>\n",
       "      <td>-0.829322</td>\n",
       "      <td>-0.518060</td>\n",
       "      <td>-0.823897</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.783520</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>-0.414415</td>\n",
       "      <td>-0.748252</td>\n",
       "      <td>-0.750814</td>\n",
       "      <td>1.583563</td>\n",
       "      <td>-0.751500</td>\n",
       "      <td>1.591151</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1531</td>\n",
       "      <td>869</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.783392</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>-0.020351</td>\n",
       "      <td>-0.748252</td>\n",
       "      <td>-0.754973</td>\n",
       "      <td>1.587318</td>\n",
       "      <td>-0.753992</td>\n",
       "      <td>1.585206</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1537</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.867961</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>-0.020351</td>\n",
       "      <td>-0.748252</td>\n",
       "      <td>-0.663835</td>\n",
       "      <td>1.678409</td>\n",
       "      <td>-0.663984</td>\n",
       "      <td>1.679387</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1536</td>\n",
       "      <td>181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126348</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>0.373713</td>\n",
       "      <td>0.546057</td>\n",
       "      <td>-0.659729</td>\n",
       "      <td>1.680508</td>\n",
       "      <td>-0.649440</td>\n",
       "      <td>1.719064</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1533</td>\n",
       "      <td>1424</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.230741</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>-1.202543</td>\n",
       "      <td>-0.748252</td>\n",
       "      <td>-0.530309</td>\n",
       "      <td>-1.625632</td>\n",
       "      <td>-0.532439</td>\n",
       "      <td>-1.582642</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1941</td>\n",
       "      <td>1626</td>\n",
       "      <td>613</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>0.213312</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>-0.512931</td>\n",
       "      <td>0.546057</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>1.355518</td>\n",
       "      <td>0.803640</td>\n",
       "      <td>1.354697</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1942</td>\n",
       "      <td>1183</td>\n",
       "      <td>1575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>-0.204226</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>1.161841</td>\n",
       "      <td>1.840366</td>\n",
       "      <td>1.261386</td>\n",
       "      <td>-0.430346</td>\n",
       "      <td>1.252985</td>\n",
       "      <td>-0.452120</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1943</td>\n",
       "      <td>1341</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>-0.033759</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>1.949968</td>\n",
       "      <td>3.134676</td>\n",
       "      <td>1.230410</td>\n",
       "      <td>-0.444465</td>\n",
       "      <td>1.251337</td>\n",
       "      <td>-0.458574</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>8.651697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1944</td>\n",
       "      <td>1081</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>-0.804235</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>-0.414415</td>\n",
       "      <td>-0.748252</td>\n",
       "      <td>-0.321698</td>\n",
       "      <td>0.183881</td>\n",
       "      <td>-0.318485</td>\n",
       "      <td>0.185968</td>\n",
       "      <td>-0.133832</td>\n",
       "      <td>-0.136994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1945</td>\n",
       "      <td>1375</td>\n",
       "      <td>819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_preprocess__link_length  num_preprocess__link_freespeed  \\\n",
       "0                       -0.719399                       -0.071818   \n",
       "1                       -0.783520                       -0.071818   \n",
       "2                       -0.783392                       -0.071818   \n",
       "3                       -0.867961                       -0.071818   \n",
       "4                        0.126348                       -0.071818   \n",
       "...                           ...                             ...   \n",
       "1941                     0.230741                       -0.071818   \n",
       "1942                     0.213312                       -0.071818   \n",
       "1943                    -0.204226                       -0.071818   \n",
       "1944                    -0.033759                       -0.071818   \n",
       "1945                    -0.804235                       -0.071818   \n",
       "\n",
       "      num_preprocess__link_capacity  num_preprocess__link_permlanes  \\\n",
       "0                          0.373713                        0.546057   \n",
       "1                         -0.414415                       -0.748252   \n",
       "2                         -0.020351                       -0.748252   \n",
       "3                         -0.020351                       -0.748252   \n",
       "4                          0.373713                        0.546057   \n",
       "...                             ...                             ...   \n",
       "1941                      -1.202543                       -0.748252   \n",
       "1942                      -0.512931                        0.546057   \n",
       "1943                       1.161841                        1.840366   \n",
       "1944                       1.949968                        3.134676   \n",
       "1945                      -0.414415                       -0.748252   \n",
       "\n",
       "      num_preprocess__start_node_x  num_preprocess__start_node_y  \\\n",
       "0                        -0.513968                     -0.829322   \n",
       "1                        -0.750814                      1.583563   \n",
       "2                        -0.754973                      1.587318   \n",
       "3                        -0.663835                      1.678409   \n",
       "4                        -0.659729                      1.680508   \n",
       "...                            ...                           ...   \n",
       "1941                     -0.530309                     -1.625632   \n",
       "1942                      0.773616                      1.355518   \n",
       "1943                      1.261386                     -0.430346   \n",
       "1944                      1.230410                     -0.444465   \n",
       "1945                     -0.321698                      0.183881   \n",
       "\n",
       "      num_preprocess__end_node_x  num_preprocess__end_node_y  \\\n",
       "0                      -0.518060                   -0.823897   \n",
       "1                      -0.751500                    1.591151   \n",
       "2                      -0.753992                    1.585206   \n",
       "3                      -0.663984                    1.679387   \n",
       "4                      -0.649440                    1.719064   \n",
       "...                          ...                         ...   \n",
       "1941                   -0.532439                   -1.582642   \n",
       "1942                    0.803640                    1.354697   \n",
       "1943                    1.252985                   -0.452120   \n",
       "1944                    1.251337                   -0.458574   \n",
       "1945                   -0.318485                    0.185968   \n",
       "\n",
       "      num_preprocess__start_count  num_preprocess__end_count  ...  \\\n",
       "0                       -0.133832                  -0.136994  ...   \n",
       "1                       -0.133832                  -0.136994  ...   \n",
       "2                       -0.133832                  -0.136994  ...   \n",
       "3                       -0.133832                  -0.136994  ...   \n",
       "4                       -0.133832                  -0.136994  ...   \n",
       "...                           ...                        ...  ...   \n",
       "1941                    -0.133832                  -0.136994  ...   \n",
       "1942                    -0.133832                  -0.136994  ...   \n",
       "1943                    -0.133832                  -0.136994  ...   \n",
       "1944                    -0.133832                   8.651697  ...   \n",
       "1945                    -0.133832                  -0.136994  ...   \n",
       "\n",
       "      text_preprocess__type_primary_link  text_preprocess__type_residential  \\\n",
       "0                                    0.0                                0.0   \n",
       "1                                    0.0                                0.0   \n",
       "2                                    1.0                                0.0   \n",
       "3                                    0.0                                0.0   \n",
       "4                                    0.0                                0.0   \n",
       "...                                  ...                                ...   \n",
       "1941                                 0.0                                0.0   \n",
       "1942                                 0.0                                0.0   \n",
       "1943                                 0.0                                0.0   \n",
       "1944                                 0.0                                0.0   \n",
       "1945                                 0.0                                0.0   \n",
       "\n",
       "      text_preprocess__type_secondary  text_preprocess__type_secondary_link  \\\n",
       "0                                 1.0                                   0.0   \n",
       "1                                 0.0                                   1.0   \n",
       "2                                 0.0                                   0.0   \n",
       "3                                 0.0                                   0.0   \n",
       "4                                 1.0                                   0.0   \n",
       "...                               ...                                   ...   \n",
       "1941                              1.0                                   0.0   \n",
       "1942                              0.0                                   0.0   \n",
       "1943                              1.0                                   0.0   \n",
       "1944                              1.0                                   0.0   \n",
       "1945                              1.0                                   0.0   \n",
       "\n",
       "      text_preprocess__type_tertiary  text_preprocess__type_unclassified  \\\n",
       "0                                0.0                                 0.0   \n",
       "1                                0.0                                 0.0   \n",
       "2                                0.0                                 0.0   \n",
       "3                                0.0                                 0.0   \n",
       "4                                0.0                                 0.0   \n",
       "...                              ...                                 ...   \n",
       "1941                             0.0                                 0.0   \n",
       "1942                             0.0                                 0.0   \n",
       "1943                             0.0                                 0.0   \n",
       "1944                             0.0                                 0.0   \n",
       "1945                             0.0                                 0.0   \n",
       "\n",
       "      remainder__link_id  remainder__link_from  remainder__link_to  \\\n",
       "0                      0                   562                 372   \n",
       "1                      1                  1531                 869   \n",
       "2                      2                  1537                1530   \n",
       "3                      3                  1536                 181   \n",
       "4                      4                  1533                1424   \n",
       "...                  ...                   ...                 ...   \n",
       "1941                1941                  1626                 613   \n",
       "1942                1942                  1183                1575   \n",
       "1943                1943                  1341                1080   \n",
       "1944                1944                  1081                1103   \n",
       "1945                1945                  1375                 819   \n",
       "\n",
       "      text_preprocess__type_trunk  \n",
       "0                             0.0  \n",
       "1                             0.0  \n",
       "2                             0.0  \n",
       "3                             0.0  \n",
       "4                             0.0  \n",
       "...                           ...  \n",
       "1941                          0.0  \n",
       "1942                          0.0  \n",
       "1943                          0.0  \n",
       "1944                          0.0  \n",
       "1945                          0.0  \n",
       "\n",
       "[1946 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te['text_preprocess__type_trunk']=0.0\n",
    "X_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preprocess__link_length</th>\n",
       "      <th>num_preprocess__link_freespeed</th>\n",
       "      <th>num_preprocess__link_capacity</th>\n",
       "      <th>num_preprocess__link_permlanes</th>\n",
       "      <th>num_preprocess__start_node_x</th>\n",
       "      <th>num_preprocess__start_node_y</th>\n",
       "      <th>num_preprocess__end_node_x</th>\n",
       "      <th>num_preprocess__end_node_y</th>\n",
       "      <th>num_preprocess__start_count</th>\n",
       "      <th>num_preprocess__end_count</th>\n",
       "      <th>...</th>\n",
       "      <th>text_preprocess__type_primary_link</th>\n",
       "      <th>text_preprocess__type_residential</th>\n",
       "      <th>text_preprocess__type_secondary</th>\n",
       "      <th>text_preprocess__type_secondary_link</th>\n",
       "      <th>text_preprocess__type_tertiary</th>\n",
       "      <th>text_preprocess__type_trunk</th>\n",
       "      <th>text_preprocess__type_unclassified</th>\n",
       "      <th>remainder__link_id</th>\n",
       "      <th>remainder__link_from</th>\n",
       "      <th>remainder__link_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.736842</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.532350</td>\n",
       "      <td>-0.505438</td>\n",
       "      <td>-0.478713</td>\n",
       "      <td>-0.509033</td>\n",
       "      <td>-0.474096</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.799751</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.390171</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.707842</td>\n",
       "      <td>1.846523</td>\n",
       "      <td>-0.708528</td>\n",
       "      <td>1.852005</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1529</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.799626</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.711397</td>\n",
       "      <td>1.850141</td>\n",
       "      <td>-0.710658</td>\n",
       "      <td>1.846278</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1535</td>\n",
       "      <td>1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882597</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.633512</td>\n",
       "      <td>1.937923</td>\n",
       "      <td>-0.633738</td>\n",
       "      <td>1.936990</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1534</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092928</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.532350</td>\n",
       "      <td>-0.630003</td>\n",
       "      <td>1.939947</td>\n",
       "      <td>-0.621308</td>\n",
       "      <td>1.975206</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1531</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29520</th>\n",
       "      <td>-0.064155</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>2.009608</td>\n",
       "      <td>3.149120</td>\n",
       "      <td>0.985277</td>\n",
       "      <td>-0.107835</td>\n",
       "      <td>1.003074</td>\n",
       "      <td>-0.122228</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>1127</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29521</th>\n",
       "      <td>1.141428</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.490161</td>\n",
       "      <td>0.532350</td>\n",
       "      <td>-0.167125</td>\n",
       "      <td>-1.586140</td>\n",
       "      <td>-0.205892</td>\n",
       "      <td>-1.542719</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>777</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29522</th>\n",
       "      <td>-0.820076</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.390171</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.341127</td>\n",
       "      <td>0.497685</td>\n",
       "      <td>-0.338478</td>\n",
       "      <td>0.498576</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>1405</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29523</th>\n",
       "      <td>-0.574670</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.390171</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>0.230536</td>\n",
       "      <td>-1.083409</td>\n",
       "      <td>0.222721</td>\n",
       "      <td>-1.083068</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1939</td>\n",
       "      <td>290</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29524</th>\n",
       "      <td>-0.318783</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>2.009608</td>\n",
       "      <td>1.840735</td>\n",
       "      <td>1.048799</td>\n",
       "      <td>0.107713</td>\n",
       "      <td>1.059648</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>221</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29525 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_preprocess__link_length  num_preprocess__link_freespeed  \\\n",
       "0                        -0.736842                        -0.06896   \n",
       "1                        -0.799751                        -0.06896   \n",
       "2                        -0.799626                        -0.06896   \n",
       "3                        -0.882597                        -0.06896   \n",
       "4                         0.092928                        -0.06896   \n",
       "...                            ...                             ...   \n",
       "29520                    -0.064155                        -0.06896   \n",
       "29521                     1.141428                        -0.06896   \n",
       "29522                    -0.820076                        -0.06896   \n",
       "29523                    -0.574670                        -0.06896   \n",
       "29524                    -0.318783                        -0.06896   \n",
       "\n",
       "       num_preprocess__link_capacity  num_preprocess__link_permlanes  \\\n",
       "0                           0.409756                        0.532350   \n",
       "1                          -0.390171                       -0.776035   \n",
       "2                           0.009792                       -0.776035   \n",
       "3                           0.009792                       -0.776035   \n",
       "4                           0.409756                        0.532350   \n",
       "...                              ...                             ...   \n",
       "29520                       2.009608                        3.149120   \n",
       "29521                      -0.490161                        0.532350   \n",
       "29522                      -0.390171                       -0.776035   \n",
       "29523                      -0.390171                       -0.776035   \n",
       "29524                       2.009608                        1.840735   \n",
       "\n",
       "       num_preprocess__start_node_x  num_preprocess__start_node_y  \\\n",
       "0                         -0.505438                     -0.478713   \n",
       "1                         -0.707842                      1.846523   \n",
       "2                         -0.711397                      1.850141   \n",
       "3                         -0.633512                      1.937923   \n",
       "4                         -0.630003                      1.939947   \n",
       "...                             ...                           ...   \n",
       "29520                      0.985277                     -0.107835   \n",
       "29521                     -0.167125                     -1.586140   \n",
       "29522                     -0.341127                      0.497685   \n",
       "29523                      0.230536                     -1.083409   \n",
       "29524                      1.048799                      0.107713   \n",
       "\n",
       "       num_preprocess__end_node_x  num_preprocess__end_node_y  \\\n",
       "0                       -0.509033                   -0.474096   \n",
       "1                       -0.708528                    1.852005   \n",
       "2                       -0.710658                    1.846278   \n",
       "3                       -0.633738                    1.936990   \n",
       "4                       -0.621308                    1.975206   \n",
       "...                           ...                         ...   \n",
       "29520                    1.003074                   -0.122228   \n",
       "29521                   -0.205892                   -1.542719   \n",
       "29522                   -0.338478                    0.498576   \n",
       "29523                    0.222721                   -1.083068   \n",
       "29524                    1.059648                    0.093764   \n",
       "\n",
       "       num_preprocess__start_count  num_preprocess__end_count  ...  \\\n",
       "0                        -0.152384                  -0.152953  ...   \n",
       "1                        -0.152384                  -0.152953  ...   \n",
       "2                        -0.152384                  -0.152953  ...   \n",
       "3                        -0.152384                  -0.152953  ...   \n",
       "4                        -0.152384                  -0.152953  ...   \n",
       "...                            ...                        ...  ...   \n",
       "29520                    -0.152384                  -0.152953  ...   \n",
       "29521                    -0.152384                  -0.152953  ...   \n",
       "29522                    -0.152384                  -0.152953  ...   \n",
       "29523                    -0.152384                  -0.152953  ...   \n",
       "29524                    -0.152384                  -0.152953  ...   \n",
       "\n",
       "       text_preprocess__type_primary_link  text_preprocess__type_residential  \\\n",
       "0                                     0.0                                0.0   \n",
       "1                                     0.0                                0.0   \n",
       "2                                     1.0                                0.0   \n",
       "3                                     0.0                                0.0   \n",
       "4                                     0.0                                0.0   \n",
       "...                                   ...                                ...   \n",
       "29520                                 0.0                                0.0   \n",
       "29521                                 0.0                                0.0   \n",
       "29522                                 0.0                                0.0   \n",
       "29523                                 0.0                                0.0   \n",
       "29524                                 0.0                                0.0   \n",
       "\n",
       "       text_preprocess__type_secondary  text_preprocess__type_secondary_link  \\\n",
       "0                                  1.0                                   0.0   \n",
       "1                                  0.0                                   1.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  0.0                                   0.0   \n",
       "4                                  1.0                                   0.0   \n",
       "...                                ...                                   ...   \n",
       "29520                              1.0                                   0.0   \n",
       "29521                              0.0                                   0.0   \n",
       "29522                              1.0                                   0.0   \n",
       "29523                              1.0                                   0.0   \n",
       "29524                              0.0                                   0.0   \n",
       "\n",
       "       text_preprocess__type_tertiary  text_preprocess__type_trunk  \\\n",
       "0                                 0.0                          0.0   \n",
       "1                                 0.0                          0.0   \n",
       "2                                 0.0                          0.0   \n",
       "3                                 0.0                          0.0   \n",
       "4                                 0.0                          0.0   \n",
       "...                               ...                          ...   \n",
       "29520                             0.0                          0.0   \n",
       "29521                             0.0                          0.0   \n",
       "29522                             0.0                          0.0   \n",
       "29523                             0.0                          0.0   \n",
       "29524                             0.0                          0.0   \n",
       "\n",
       "       text_preprocess__type_unclassified  remainder__link_id  \\\n",
       "0                                     0.0                   0   \n",
       "1                                     0.0                   1   \n",
       "2                                     0.0                   2   \n",
       "3                                     0.0                   3   \n",
       "4                                     0.0                   4   \n",
       "...                                   ...                 ...   \n",
       "29520                                 0.0                1936   \n",
       "29521                                 0.0                1937   \n",
       "29522                                 0.0                1938   \n",
       "29523                                 0.0                1939   \n",
       "29524                                 0.0                1940   \n",
       "\n",
       "       remainder__link_from  remainder__link_to  \n",
       "0                       644                 369  \n",
       "1                      1529                1042  \n",
       "2                      1535                1528  \n",
       "3                      1534                 171  \n",
       "4                      1531                1411  \n",
       "...                     ...                 ...  \n",
       "29520                  1127                1142  \n",
       "29521                   777                1252  \n",
       "29522                  1405                 828  \n",
       "29523                   290                 317  \n",
       "29524                   221                 841  \n",
       "\n",
       "[29525 rows x 27 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "result_final_with_test = {}\n",
    "for name, model in models.items():\n",
    "    X_t_reduced = X_t[results_feature[name]['selected_feature']]\n",
    "    X_te_reduced = X_te[results_feature[name]['selected_feature']]\n",
    "    result_final_with_test[name] = evaluate_models_with_test(model, X_t_reduced, y_t, X_te_reduced, y_te)\n",
    "result_final_with_test\n",
    "with open('result_sparse_final(wo gpr).pkl', 'wb') as file:\n",
    "    pickle.dump(result_final_with_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 3.080183348962724, 'MSE': 12.419092563002643},\n",
       " 'Lasso': {'MAE': 3.1106409525709178, 'MSE': 12.503019186623643},\n",
       " 'Ridge': {'MAE': 3.0806624598898042, 'MSE': 12.423992202135015},\n",
       " 'SVR': {'MAE': 6.442003396245811, 'MSE': 45.04902062571267},\n",
       " 'Random Forest': {'MAE': 3.082777998593182, 'MSE': 17.22896160836622},\n",
       " 'Gradient Boosting': {'MAE': 3.0093110252525332, 'MSE': 16.819822124756406},\n",
       " 'Artificial Neural Network': {'MAE': 3.263439721629703,\n",
       "  'MSE': 13.186400138371253}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final_with_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize a list to hold trips\n",
    "# trips = []\n",
    "# current_trip = [df_od_pairs.iloc[0]['origin']]  # Start with the first origin\n",
    "# \n",
    "# # Iterate over the DataFrame rows\n",
    "# for i, row in df_od_pairs.iterrows():\n",
    "#     current_trip.append(row['destination'])  # Always add the destination\n",
    "#     # Check if the next origin matches the current destination\n",
    "#     if i + 1 < len(df_od_pairs) and row['destination'] != df_od_pairs.iloc[i + 1]['origin']:\n",
    "#         # If it doesn't, the current trip has ended\n",
    "#         trips.append(current_trip)\n",
    "#         current_trip = [df_od_pairs.iloc[i + 1]['origin']]  # Start a new trip\n",
    "# \n",
    "# # Add the last trip if it wasn't already added\n",
    "# if current_trip not in trips:\n",
    "#     trips.append(current_trip)\n",
    "\n",
    "\n",
    "# from collections import Counter\n",
    "# # Flatten the list of trips into a single list of nodes including origins and destinations\n",
    "# all_nodes = [node for trip in trips for node in trip]\n",
    "# \n",
    "# # Use Counter to count the occurrences of each node\n",
    "# node_trip_counts = Counter(all_nodes)\n",
    "# \n",
    "# df_node_trip_counts = pd.DataFrame.from_dict(node_trip_counts, orient='index').reset_index()\n",
    "# df_node_trip_counts.columns = ['node_id', 'trip_amount']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
