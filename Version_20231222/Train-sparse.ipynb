{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:19:43.963037300Z",
     "start_time": "2024-01-05T00:19:43.928475600Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import expon, reciprocal, uniform\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, DotProduct, ExpSineSquared, RationalQuadratic\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:08:59.821733Z",
     "start_time": "2024-01-05T00:08:33.233652700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file_list, df_activities, df_links_network):\n",
    "    data_frames = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data['link_counts'], dict):\n",
    "                data['link_counts'] = data['link_counts'].values()\n",
    "            df_links = pd.DataFrame({\n",
    "                'link_id': data['links_id'],\n",
    "                'link_from': data['link_from'],\n",
    "                'link_to': data['link_to'],\n",
    "                'link_length': data['link_length'],\n",
    "                'link_freespeed': data['link_freespeed'],\n",
    "                'link_capacity': data['link_capacity'],\n",
    "                'link_permlanes': data['link_permlanes'],\n",
    "                'link_counts': data['link_counts']\n",
    "            })\n",
    "            df_nodes = pd.DataFrame({\n",
    "                'node_id': data['nodes_id'],\n",
    "                'node_x': data['nodes_x'],\n",
    "                'node_y': data['nodes_y']\n",
    "            })\n",
    "            df_od_pairs = pd.DataFrame(data['o_d_pairs'], columns=['origin', 'destination'])\n",
    "            \n",
    "            df_work = pd.DataFrame({\n",
    "                        'work_x': data['work_x'],\n",
    "                        'work_y': data['work_y'],\n",
    "                        'go_to_work': data['go_to_work']\n",
    "            })\n",
    "            df_home = pd.DataFrame({\n",
    "                'home_x': data['home_x'],\n",
    "                'home_y': data['home_y'],\n",
    "                'go_to_home': data['go_to_home']\n",
    "            })\n",
    "            \n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_from', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'start_node_x', 'node_y': 'start_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_to', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'end_node_x', 'node_y': 'end_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True) \n",
    "            \n",
    "            origin_counts = df_od_pairs['origin'].value_counts()\n",
    "            df_origin_counts = origin_counts.reset_index()\n",
    "            df_origin_counts.columns = ['origin', 'start_count']\n",
    "            destination_counts = df_od_pairs['destination'].value_counts()\n",
    "            df_destination_counts = destination_counts.reset_index()\n",
    "            df_destination_counts.columns = ['destination', 'end_count']\n",
    "            df_links = df_links.merge(df_origin_counts, how='left', left_on='link_from', right_on='origin')\n",
    "            df_links.drop('origin', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_destination_counts, how='left', left_on='link_to', right_on='destination')\n",
    "            df_links.drop('destination', axis=1, inplace=True)\n",
    "            df_links[['start_count','end_count']] = df_links[['start_count','end_count']].fillna(-1)\n",
    "            \n",
    "            # Calculate time of go_to_work and go_to_sum\n",
    "            df_act_work = df_activities[df_activities['activity_type_main']=='work'].drop(['end_time'], axis=1)\n",
    "            df_act_work = df_act_work.merge(df_work, how='left', left_on=['x','y'], right_on=['work_x','work_y'])\n",
    "            df_act_work.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_work_agg = df_act_work.groupby(by=\"link\")['go_to_work'].sum().reset_index(drop=False)\n",
    "            df_act_home = df_activities[df_activities['activity_type_main']=='home'].drop(['end_time'], axis=1)\n",
    "            df_act_home = df_act_home.merge(df_home, how='left', left_on=['x','y'], right_on=['home_x','home_y'])\n",
    "            df_act_home.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_home_agg = df_act_home.groupby(by=\"link\")['go_to_home'].sum().reset_index(drop=False)\n",
    "            df_act_agg = df_act_home_agg.merge(df_act_work_agg, how='outer', on='link')\n",
    "            df_act_agg.fillna(0, inplace=True)\n",
    "            df_act_agg['go_to_sum'] = df_act_agg['go_to_home'] + df_act_agg['go_to_work']\n",
    "\n",
    "            df_rushhr = df_activities[df_activities['end_time']!=-1]\n",
    "            df_rushhr.loc[:, 'rush_hour'] = 0\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('08:00:00'), pd.to_timedelta('10:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('16:00:00'), pd.to_timedelta('19:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
    "            df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
    "            \n",
    "            df_maxduragg = df_activities[df_activities['max_dur']!=-1].groupby(by='link')['max_dur'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_activities['cemdapStopDuration_s'] = df_activities['cemdapStopDuration_s'].astype(float)\n",
    "            df_cemagg = df_activities[df_activities['cemdapStopDuration_s']!=-1].groupby(by='link')['cemdapStopDuration_s'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_temp = df_links.merge(df_links_network, how='left', on=['start_node_x','start_node_y','end_node_x','end_node_y'])\n",
    "            df_temp = df_temp[['link_id_x','link_from','link_to','link_id_y','from', 'to', 'type']]\n",
    "            df_temp = df_temp.merge(df_act_agg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_rushhragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_maxduragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_cemagg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.fillna({'cemdapStopDuration_s':-1, 'max_dur':-1, 'rush_hour': -1, 'go_to_sum': -1}, inplace=True)\n",
    "            df_temp = df_temp[['link_id_x', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s', 'type']]\n",
    "            \n",
    "            df_links = df_links.merge(df_temp, how='left', left_on='link_id', right_on='link_id_x')\n",
    "            df_links.drop('link_id_x', axis=1, inplace=True)\n",
    "        data_frames.append(df_links)\n",
    "    return pd.concat(data_frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.loc[:, 'rush_hour'] = 0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13332\\3992581593.py:73: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n"
     ]
    }
   ],
   "source": [
    "df_train = []\n",
    "for i in range(0, 10):\n",
    "    train_files = f'Data/sparseWorlds/Train/po-1/s-{i}.json'\n",
    "    df_activities = pd.read_pickle(f'Data/sparseWorlds/Train/po-1/df_activities_{i}.pkl')\n",
    "    df_links_network = pd.read_pickle(f'Data/sparseWorlds/Train/po-1/df_links_network_{i}.pkl')\n",
    "    train_data = load_data([train_files], df_activities, df_links_network)\n",
    "    df_train.append(train_data)\n",
    "train_data_all = pd.concat(df_train, ignore_index=True)\n",
    "\n",
    "df_validate = []\n",
    "for i in range(10, 15):\n",
    "    validate_files = f'Data/sparseWorlds/Validate/po-1/s-{i}.json'\n",
    "    df_activities = pd.read_pickle(f'Data/sparseWorlds/Validate/po-1/df_activities_{i}.pkl')\n",
    "    df_links_network = pd.read_pickle(f'Data/sparseWorlds/Validate/po-1/df_links_network_{i}.pkl')\n",
    "    validate_data = load_data([validate_files], df_activities, df_links_network)\n",
    "    df_validate.append(validate_data)\n",
    "validate_data_all = pd.concat(df_validate, ignore_index=True)\n",
    "    \n",
    "df_test = []\n",
    "for i in range(15, 20):\n",
    "    test_files = f'Data/sparseWorlds/Test/po-1/s-{i}.json'\n",
    "    df_activities = pd.read_pickle(f'Data/sparseWorlds/Test/po-1/df_activities_{i}.pkl')\n",
    "    df_links_network = pd.read_pickle(f'Data/sparseWorlds/Test/po-1/df_links_network_{i}.pkl')\n",
    "    test_data = load_data([test_files], df_activities, df_links_network)\n",
    "    df_test.append(test_data)\n",
    "test_data_all = pd.concat(df_test, ignore_index=True)\n",
    "\n",
    "Big_train_data = pd.concat([train_data_all, validate_data_all], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:31.053189200Z",
     "start_time": "2024-01-05T00:25:30.986858300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['link_length', 'link_freespeed', 'link_capacity', 'link_permlanes', 'start_node_x', 'start_node_y', 'end_node_x', 'end_node_y', 'start_count', 'end_count', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s']\n",
    "category_feature = ['type']\n",
    "X_t = Big_train_data.drop(columns=['link_counts'])\n",
    "y_t = Big_train_data['link_counts']\n",
    "X_te = test_data.drop(columns=['link_counts'])\n",
    "y_te = test_data['link_counts']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ct = ColumnTransformer(\n",
    "     [(\"num_preprocess\", scaler, numerical_features),\n",
    "      (\"text_preprocess\", ohe, category_feature)], remainder='passthrough').set_output(transform=\"pandas\")\n",
    "X_t = ct.fit_transform(X_t) \n",
    "X_te = ct.fit_transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:38.793260300Z",
     "start_time": "2024-01-05T00:25:38.746926800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': LassoCV(cv=kf),\n",
    "    'Ridge': RidgeCV(cv=kf),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Artificial Neural Network': MLPRegressor(),\n",
    "#     'Gaussian Process Regression': GaussianProcessRegressor(kernel=RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0), alpha=0.1, n_restarts_optimizer=3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:31:29.592973900Z",
     "start_time": "2024-01-05T00:28:22.015669500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression done\n",
      "Lasso done\n",
      "Ridge done\n",
      "SVR done\n",
      "Random Forest done\n",
      "Gradient Boosting done\n",
      "Artificial Neural Network done\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate models\n",
    "def evaluate_models(models, X_train, y_train):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         mse = mean_squared_error(y_test, y_pred)\n",
    "#         mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "        mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "        # Define the cross-validation strategy (e.g., 5-fold cross-validation)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # Perform k-fold cross-validation and calculate MSE and MAE\n",
    "        mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mse_scorer)\n",
    "        mae_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mae_scorer)\n",
    "\n",
    "        # Display the mean MSE and MAE across folds\n",
    "        mean_mse = -mse_scores.mean()\n",
    "        mean_mae = -mae_scores.mean()\n",
    "        std_mse = mse_scores.std()\n",
    "        # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        # r2 = r2_score(y_test, y_pred)\n",
    "        print(name + \" done\")\n",
    "        \n",
    "        results[name] = {'MAE': mean_mae, 'MSE': mean_mse, 'MSE_std': std_mse}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def feature_select_models(models, X_train, y_train):\n",
    "    mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name not in ['SVR', 'Artificial Neural Network', 'Gaussian Process Regression']:\n",
    "            selector = RFECV(model, step=1, cv=kf, scoring=mse_scorer).fit(X_train, y_train)\n",
    "            print(f'{name} selection done')\n",
    "\n",
    "        else:\n",
    "            # Fit Random Forest to get feature importances\n",
    "            rf = RandomForestRegressor()\n",
    "            rf.fit(X_train, y_train)\n",
    "            # Select features based on importances\n",
    "            selector = RFECV(estimator=rf, step=1, cv=kf, scoring=mse_scorer).fit(X_train, y_train)\n",
    "            print(f'{name} selection done')\n",
    "            \n",
    "        selected_features = X_train.columns[selector.support_]\n",
    "        X_train_reduced = X_train[selected_features] \n",
    "        mse_scores = cross_val_score(model, X_train_reduced, y_train, cv=kf, scoring=mse_scorer)\n",
    "        mse = -mse_scores.mean()\n",
    "        mse_std = mse_scores.std()           \n",
    "        mae_scores = cross_val_score(model, X_train_reduced, y_train, cv=kf, scoring=mae_scorer)\n",
    "        mean_mae = -mae_scores.mean()\n",
    "\n",
    "        results[name] = {'MAE': mean_mae, 'MSE': mse, 'MSE_std': mse_std, 'selected_feature': selected_features}\n",
    "\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Train and evaluate\n",
    "results = evaluate_models(models, X_t, y_t)\n",
    "\n",
    "# results_feature = feature_select_models(models, X_t, y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preprocess__link_length</th>\n",
       "      <th>num_preprocess__link_freespeed</th>\n",
       "      <th>num_preprocess__link_capacity</th>\n",
       "      <th>num_preprocess__link_permlanes</th>\n",
       "      <th>num_preprocess__start_node_x</th>\n",
       "      <th>num_preprocess__start_node_y</th>\n",
       "      <th>num_preprocess__end_node_x</th>\n",
       "      <th>num_preprocess__end_node_y</th>\n",
       "      <th>num_preprocess__start_count</th>\n",
       "      <th>num_preprocess__end_count</th>\n",
       "      <th>...</th>\n",
       "      <th>text_preprocess__type_primary_link</th>\n",
       "      <th>text_preprocess__type_residential</th>\n",
       "      <th>text_preprocess__type_secondary</th>\n",
       "      <th>text_preprocess__type_secondary_link</th>\n",
       "      <th>text_preprocess__type_tertiary</th>\n",
       "      <th>text_preprocess__type_trunk</th>\n",
       "      <th>text_preprocess__type_unclassified</th>\n",
       "      <th>remainder__link_id</th>\n",
       "      <th>remainder__link_from</th>\n",
       "      <th>remainder__link_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.736842</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.532350</td>\n",
       "      <td>-0.505438</td>\n",
       "      <td>-0.478713</td>\n",
       "      <td>-0.509033</td>\n",
       "      <td>-0.474096</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.799751</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.390171</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.707842</td>\n",
       "      <td>1.846523</td>\n",
       "      <td>-0.708528</td>\n",
       "      <td>1.852005</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1529</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.799626</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.711397</td>\n",
       "      <td>1.850141</td>\n",
       "      <td>-0.710658</td>\n",
       "      <td>1.846278</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1535</td>\n",
       "      <td>1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882597</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.633512</td>\n",
       "      <td>1.937923</td>\n",
       "      <td>-0.633738</td>\n",
       "      <td>1.936990</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1534</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092928</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.532350</td>\n",
       "      <td>-0.630003</td>\n",
       "      <td>1.939947</td>\n",
       "      <td>-0.621308</td>\n",
       "      <td>1.975206</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1531</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29520</th>\n",
       "      <td>-0.064155</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>2.009608</td>\n",
       "      <td>3.149120</td>\n",
       "      <td>0.985277</td>\n",
       "      <td>-0.107835</td>\n",
       "      <td>1.003074</td>\n",
       "      <td>-0.122228</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>1127</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29521</th>\n",
       "      <td>1.141428</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.490161</td>\n",
       "      <td>0.532350</td>\n",
       "      <td>-0.167125</td>\n",
       "      <td>-1.586140</td>\n",
       "      <td>-0.205892</td>\n",
       "      <td>-1.542719</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>777</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29522</th>\n",
       "      <td>-0.820076</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.390171</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>-0.341127</td>\n",
       "      <td>0.497685</td>\n",
       "      <td>-0.338478</td>\n",
       "      <td>0.498576</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>1405</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29523</th>\n",
       "      <td>-0.574670</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.390171</td>\n",
       "      <td>-0.776035</td>\n",
       "      <td>0.230536</td>\n",
       "      <td>-1.083409</td>\n",
       "      <td>0.222721</td>\n",
       "      <td>-1.083068</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1939</td>\n",
       "      <td>290</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29524</th>\n",
       "      <td>-0.318783</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>2.009608</td>\n",
       "      <td>1.840735</td>\n",
       "      <td>1.048799</td>\n",
       "      <td>0.107713</td>\n",
       "      <td>1.059648</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>-0.152384</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>221</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29525 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_preprocess__link_length  num_preprocess__link_freespeed  \\\n",
       "0                        -0.736842                        -0.06896   \n",
       "1                        -0.799751                        -0.06896   \n",
       "2                        -0.799626                        -0.06896   \n",
       "3                        -0.882597                        -0.06896   \n",
       "4                         0.092928                        -0.06896   \n",
       "...                            ...                             ...   \n",
       "29520                    -0.064155                        -0.06896   \n",
       "29521                     1.141428                        -0.06896   \n",
       "29522                    -0.820076                        -0.06896   \n",
       "29523                    -0.574670                        -0.06896   \n",
       "29524                    -0.318783                        -0.06896   \n",
       "\n",
       "       num_preprocess__link_capacity  num_preprocess__link_permlanes  \\\n",
       "0                           0.409756                        0.532350   \n",
       "1                          -0.390171                       -0.776035   \n",
       "2                           0.009792                       -0.776035   \n",
       "3                           0.009792                       -0.776035   \n",
       "4                           0.409756                        0.532350   \n",
       "...                              ...                             ...   \n",
       "29520                       2.009608                        3.149120   \n",
       "29521                      -0.490161                        0.532350   \n",
       "29522                      -0.390171                       -0.776035   \n",
       "29523                      -0.390171                       -0.776035   \n",
       "29524                       2.009608                        1.840735   \n",
       "\n",
       "       num_preprocess__start_node_x  num_preprocess__start_node_y  \\\n",
       "0                         -0.505438                     -0.478713   \n",
       "1                         -0.707842                      1.846523   \n",
       "2                         -0.711397                      1.850141   \n",
       "3                         -0.633512                      1.937923   \n",
       "4                         -0.630003                      1.939947   \n",
       "...                             ...                           ...   \n",
       "29520                      0.985277                     -0.107835   \n",
       "29521                     -0.167125                     -1.586140   \n",
       "29522                     -0.341127                      0.497685   \n",
       "29523                      0.230536                     -1.083409   \n",
       "29524                      1.048799                      0.107713   \n",
       "\n",
       "       num_preprocess__end_node_x  num_preprocess__end_node_y  \\\n",
       "0                       -0.509033                   -0.474096   \n",
       "1                       -0.708528                    1.852005   \n",
       "2                       -0.710658                    1.846278   \n",
       "3                       -0.633738                    1.936990   \n",
       "4                       -0.621308                    1.975206   \n",
       "...                           ...                         ...   \n",
       "29520                    1.003074                   -0.122228   \n",
       "29521                   -0.205892                   -1.542719   \n",
       "29522                   -0.338478                    0.498576   \n",
       "29523                    0.222721                   -1.083068   \n",
       "29524                    1.059648                    0.093764   \n",
       "\n",
       "       num_preprocess__start_count  num_preprocess__end_count  ...  \\\n",
       "0                        -0.152384                  -0.152953  ...   \n",
       "1                        -0.152384                  -0.152953  ...   \n",
       "2                        -0.152384                  -0.152953  ...   \n",
       "3                        -0.152384                  -0.152953  ...   \n",
       "4                        -0.152384                  -0.152953  ...   \n",
       "...                            ...                        ...  ...   \n",
       "29520                    -0.152384                  -0.152953  ...   \n",
       "29521                    -0.152384                  -0.152953  ...   \n",
       "29522                    -0.152384                  -0.152953  ...   \n",
       "29523                    -0.152384                  -0.152953  ...   \n",
       "29524                    -0.152384                  -0.152953  ...   \n",
       "\n",
       "       text_preprocess__type_primary_link  text_preprocess__type_residential  \\\n",
       "0                                     0.0                                0.0   \n",
       "1                                     0.0                                0.0   \n",
       "2                                     1.0                                0.0   \n",
       "3                                     0.0                                0.0   \n",
       "4                                     0.0                                0.0   \n",
       "...                                   ...                                ...   \n",
       "29520                                 0.0                                0.0   \n",
       "29521                                 0.0                                0.0   \n",
       "29522                                 0.0                                0.0   \n",
       "29523                                 0.0                                0.0   \n",
       "29524                                 0.0                                0.0   \n",
       "\n",
       "       text_preprocess__type_secondary  text_preprocess__type_secondary_link  \\\n",
       "0                                  1.0                                   0.0   \n",
       "1                                  0.0                                   1.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  0.0                                   0.0   \n",
       "4                                  1.0                                   0.0   \n",
       "...                                ...                                   ...   \n",
       "29520                              1.0                                   0.0   \n",
       "29521                              0.0                                   0.0   \n",
       "29522                              1.0                                   0.0   \n",
       "29523                              1.0                                   0.0   \n",
       "29524                              0.0                                   0.0   \n",
       "\n",
       "       text_preprocess__type_tertiary  text_preprocess__type_trunk  \\\n",
       "0                                 0.0                          0.0   \n",
       "1                                 0.0                          0.0   \n",
       "2                                 0.0                          0.0   \n",
       "3                                 0.0                          0.0   \n",
       "4                                 0.0                          0.0   \n",
       "...                               ...                          ...   \n",
       "29520                             0.0                          0.0   \n",
       "29521                             0.0                          0.0   \n",
       "29522                             0.0                          0.0   \n",
       "29523                             0.0                          0.0   \n",
       "29524                             0.0                          0.0   \n",
       "\n",
       "       text_preprocess__type_unclassified  remainder__link_id  \\\n",
       "0                                     0.0                   0   \n",
       "1                                     0.0                   1   \n",
       "2                                     0.0                   2   \n",
       "3                                     0.0                   3   \n",
       "4                                     0.0                   4   \n",
       "...                                   ...                 ...   \n",
       "29520                                 0.0                1936   \n",
       "29521                                 0.0                1937   \n",
       "29522                                 0.0                1938   \n",
       "29523                                 0.0                1939   \n",
       "29524                                 0.0                1940   \n",
       "\n",
       "       remainder__link_from  remainder__link_to  \n",
       "0                       644                 369  \n",
       "1                      1529                1042  \n",
       "2                      1535                1528  \n",
       "3                      1534                 171  \n",
       "4                      1531                1411  \n",
       "...                     ...                 ...  \n",
       "29520                  1127                1142  \n",
       "29521                   777                1252  \n",
       "29522                  1405                 828  \n",
       "29523                   290                 317  \n",
       "29524                   221                 841  \n",
       "\n",
       "[29525 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 4.693113446842107,\n",
       "  'MSE': 55.849006153897605,\n",
       "  'MSE_std': 2.432367097366999},\n",
       " 'Lasso': {'MAE': 4.73523872550065,\n",
       "  'MSE': 56.36714670885806,\n",
       "  'MSE_std': 2.4722245661994404},\n",
       " 'Ridge': {'MAE': 4.692299720318795,\n",
       "  'MSE': 55.84925513445673,\n",
       "  'MSE_std': 2.4336838277175006},\n",
       " 'SVR': {'MAE': 3.796789836594848,\n",
       "  'MSE': 66.91232244253311,\n",
       "  'MSE_std': 3.0398415798701195},\n",
       " 'Random Forest': {'MAE': 3.8049070279424213,\n",
       "  'MSE': 45.3557022895851,\n",
       "  'MSE_std': 1.9916994575650346},\n",
       " 'Gradient Boosting': {'MAE': 4.435219723809254,\n",
       "  'MSE': 51.70751836160465,\n",
       "  'MSE_std': 2.3147557241346983},\n",
       " 'Artificial Neural Network': {'MAE': 5.1972694271238336,\n",
       "  'MSE': 65.93310931246707,\n",
       "  'MSE_std': 16.515316185356948}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before hyperparametertuning\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('result_after_featureselection(wo gpr).pkl', 'wb') as file:\n",
    "    pickle.dump(results_feature, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 19.000541966353587, 'MSE': 1350.56069460534},\n",
       " 'Lasso': {'MAE': 22.610703312854127, 'MSE': 1679.4760262080995},\n",
       " 'Ridge': {'MAE': 18.989592790164192, 'MSE': 1349.7480663335148},\n",
       " 'SVR': {'MAE': 23.793351948629688, 'MSE': 1756.1078902638878},\n",
       " 'Random Forest': {'MAE': 17.635830260141653, 'MSE': 2015.2344103327919},\n",
       " 'Gradient Boosting': {'MAE': 15.969274342418169, 'MSE': 1596.9989870917648},\n",
       " 'Artificial Neural Network': {'MAE': 21.345942437519778,\n",
       "  'MSE': 1888.5103715269568}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after hyperparametertuning\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 19.47148762371669,\n",
       "  'MSE': 874.7590684153923,\n",
       "  'selected_feature': Index(['link_length', 'link_freespeed', 'link_capacity', 'link_permlanes',\n",
       "         'start_node_x', 'start_node_y', 'end_node_x', 'end_node_y',\n",
       "         'start_count'],\n",
       "        dtype='object')},\n",
       " 'Lasso': {'MAE': 21.29080224423866,\n",
       "  'MSE': 995.8290100956449,\n",
       "  'selected_feature': Index(['link_id', 'link_permlanes', 'start_node_x', 'start_node_y',\n",
       "         'end_node_x', 'end_node_y', 'start_count', 'end_count', 'go_to_sum'],\n",
       "        dtype='object')},\n",
       " 'Ridge': {'MAE': 18.855381894067843,\n",
       "  'MSE': 831.7957770846882,\n",
       "  'selected_feature': Index(['link_length', 'link_freespeed', 'link_capacity', 'link_permlanes',\n",
       "         'start_node_x', 'start_node_y', 'end_node_y', 'start_count',\n",
       "         'end_count'],\n",
       "        dtype='object')},\n",
       " 'SVR': {'MAE': 21.113999718501606,\n",
       "  'MSE': 998.1921690104024,\n",
       "  'selected_feature': Index(['link_id', 'link_length', 'link_freespeed', 'link_capacity',\n",
       "         'link_permlanes', 'start_node_x', 'start_node_y', 'end_node_x',\n",
       "         'end_node_y'],\n",
       "        dtype='object')},\n",
       " 'Random Forest': {'MAE': 16.64219759429435,\n",
       "  'MSE': 752.4379897068696,\n",
       "  'selected_feature': Index(['link_id', 'link_length', 'link_freespeed', 'link_capacity',\n",
       "         'link_permlanes', 'start_node_x', 'start_node_y', 'end_node_x',\n",
       "         'end_node_y'],\n",
       "        dtype='object')},\n",
       " 'Gradient Boosting': {'MAE': 17.670831896678532,\n",
       "  'MSE': 716.0204825248611,\n",
       "  'selected_feature': Index(['link_length', 'link_freespeed', 'link_capacity', 'link_permlanes',\n",
       "         'start_node_x', 'start_node_y', 'end_node_x', 'end_node_y',\n",
       "         'start_count'],\n",
       "        dtype='object')},\n",
       " 'Artificial Neural Network': {'MAE': 26.354717993482414,\n",
       "  'MSE': 1077.2371661655832,\n",
       "  'selected_feature': Index(['link_id', 'link_length', 'link_freespeed', 'link_capacity',\n",
       "         'link_permlanes', 'start_node_x', 'start_node_y', 'end_node_x',\n",
       "         'end_node_y'],\n",
       "        dtype='object')}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T15:58:29.829296Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 70 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-2.06753800e+21 -1.78347029e+03 -3.21274664e+21 -4.52036712e+58\n",
      " -2.11726699e+03 -1.78346984e+03 -1.78347029e+03 -1.78347029e+03\n",
      "             nan             nan -6.24658420e+19 -6.10801167e+12\n",
      " -1.96408398e+16 -1.78347029e+03             nan -1.78347029e+03\n",
      " -1.78347029e+03 -5.64219848e+20             nan -5.87544447e+21\n",
      "             nan -1.78347029e+03 -1.78347029e+03             nan\n",
      " -1.78347029e+03             nan -4.64578815e+15 -1.77140788e+03\n",
      "             nan -1.78347029e+03 -1.18411241e+16 -1.92220132e+03\n",
      " -1.78347029e+03 -1.78346995e+03             nan -2.11002684e+03\n",
      " -1.07400560e+17             nan             nan -1.78347029e+03\n",
      " -2.04274595e+03 -1.78347029e+03 -1.78347028e+03 -1.78347029e+03\n",
      " -1.78347029e+03 -1.78346908e+03 -1.77144765e+03 -1.78204420e+03\n",
      " -1.78347029e+03 -1.78347029e+03 -1.78347029e+03 -1.78070475e+03\n",
      " -2.11794703e+69 -1.78347029e+03 -1.78347029e+03 -2.47674823e+13\n",
      " -2.09596395e+22 -7.27577476e+20 -1.78347029e+03 -1.78347029e+03\n",
      " -5.24770013e+17 -2.66758547e+48             nan -8.75319761e+11\n",
      " -1.78347029e+03 -8.04400389e+14 -1.30787052e+23             nan\n",
      " -1.37463938e+10             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 25.383309585489613, 'epsilon': 0.01, 'gamma': 2.1969677491639246, 'kernel': 'rbf'}\n",
      "SVR(C=25.383309585489613, epsilon=0.01, gamma=2.1969677491639246, max_iter=2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid_svr = {\n",
    "    'C': reciprocal(1e-4, 1e3),  # Extended range for the regularization parameter\n",
    "    'gamma': reciprocal(1e-4, 1e2),  # Including specific gamma values\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Focusing on RBF kernel\n",
    "    'epsilon': [0.01, 0.1, 0.2],  # Epsilon in the epsilon-SVR model\n",
    "}\n",
    "\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search_svr = RandomizedSearchCV(SVR(max_iter=2000), param_grid_svr, n_iter=80, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "random_search_svr.fit(X_t, y_t)\n",
    "print(random_search_svr.best_params_)\n",
    "print(random_search_svr.best_estimator_)\n",
    "print(random_search_svr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T01:20:56.486270700Z",
     "start_time": "2023-12-31T01:19:49.061059700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "{'criterion': 'friedman_mse', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "RandomForestRegressor(criterion='friedman_mse', max_depth=5, n_estimators=200,\n",
      "                      random_state=42)\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion':['friedman_mse']\n",
    "}\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "grid_search_rf.fit(X_t, y_t)\n",
    "\n",
    "print(grid_search_rf.best_params_)\n",
    "print(grid_search_rf.best_estimator_)\n",
    "print(grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T14:55:59.094098400Z",
     "start_time": "2023-12-31T14:48:54.215646500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15896\\4229038057.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgrid_search_gb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_gb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgrid_search_gb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search_gb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search_gb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Varied learning rates for gradient boosting\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'subsample': [0.8, 1.0],  # Fraction of samples to be used for fitting individual base learners\n",
    "}\n",
    "\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_gb = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_gb, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "grid_search_gb.fit(X_t, y_t)\n",
    "print(grid_search_gb.best_params_)\n",
    "print(grid_search_gb.best_estimator_)\n",
    "print(grid_search_gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T19:56:11.590867600Z",
     "start_time": "2024-01-02T19:50:33.301610200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 60 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-1.86563041e+03 -1.11854254e+03 -1.84244284e+03 -1.13757887e+03\n",
      " -1.83398930e+03 -1.31004265e+03 -1.87286169e+03 -1.15885216e+03\n",
      " -1.84286007e+03 -1.26657990e+03 -1.85422786e+03 -1.13490388e+03\n",
      " -1.81175536e+03 -1.14374680e+03 -1.82734857e+03 -1.15570608e+03\n",
      " -1.83311349e+03 -1.14598088e+03 -1.84129863e+03 -1.23583309e+03\n",
      " -1.80666932e+03 -1.13699446e+03 -1.83771222e+03 -1.14234487e+03\n",
      " -1.84250819e+03 -1.29638924e+03 -1.83180786e+03 -1.16942667e+03\n",
      " -1.84268122e+03 -1.21379560e+03 -8.48523766e+20 -1.16028209e+03\n",
      " -5.01611135e+12 -1.19183664e+03             nan -1.23202037e+03\n",
      "             nan -1.26948358e+03             nan -1.23640000e+03\n",
      " -8.48523937e+20 -1.25983731e+03 -5.01609670e+12 -1.24090603e+03\n",
      "             nan -1.29318375e+03             nan -1.35751659e+03\n",
      "             nan -1.20704770e+03 -8.48525641e+20 -1.11242170e+03\n",
      " -5.01595022e+12 -1.18502254e+03             nan -1.22700677e+03\n",
      "             nan -1.22550436e+03             nan -1.23931689e+03]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'solver': 'adam'}\n",
      "MLPRegressor(alpha=0.01, hidden_layer_sizes=(50,), max_iter=2000,\n",
      "             random_state=42)\n",
      "5739.742620293232 33.459636948944656\n"
     ]
    }
   ],
   "source": [
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100), (30, 30, 30)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "}\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_mlp = GridSearchCV(MLPRegressor(max_iter=2000, random_state=42), param_grid_mlp, cv=kf, n_jobs=-1, verbose=10, scoring=mse_scorer)\n",
    "grid_search_mlp.fit(X_t, y_t)\n",
    "print(grid_search_mlp.best_params_)\n",
    "print(grid_search_mlp.best_estimator_)\n",
    "print(grid_search_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T21:55:20.525741600Z",
     "start_time": "2024-01-01T20:54:36.357249300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15896\\1928377076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Initialize GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgrid_search_gpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrid_search_gpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search_gpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m         \u001b[0mcv_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2305\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2307\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    287\u001b[0m                 \u001b[1;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[1;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0."
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, DotProduct\n",
    "import numpy as np\n",
    "param_grid = {\n",
    "    'kernel': [ConstantKernel (1.0, (1e-1, 1e1)) * RBF(1.0, (1e-2, 1e2))],\n",
    "    'alpha': [ 1e-2, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "gpr = GaussianProcessRegressor(copy_X_train=False)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_gpr = RandomizedSearchCV(gpr, param_grid, n_iter=5, cv=0, scoring='neg_mean_squared_error', n_jobs=-1, verbose=10)\n",
    "grid_search_gpr.fit(X_t, y_t)\n",
    "\n",
    "print(grid_search_gpr.best_params_)\n",
    "print(grid_search_gpr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models_with_test(model, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "      \n",
    "    results = {'MAE': mae, 'MSE': mse}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ln_model = models['Linear Regression']\n",
    "ln_X_t = X_t[results_feature['Linear Regression']['selected_feature']]\n",
    "ln_X_te = X_te[results_feature['Linear Regression']['selected_feature']]\n",
    "\n",
    "ln_results = evaluate_models_with_test(ln_model, ln_X_t, y_t, ln_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lasso_model = models['Lasso']\n",
    "lasso_X_t = X_t[results_feature['Lasso']['selected_feature']]\n",
    "lasso_X_te = X_te[results_feature['Lasso']['selected_feature']]\n",
    "\n",
    "lasso_results = evaluate_models_with_test(lasso_model, lasso_X_t, y_t, lasso_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model = models['Ridge']\n",
    "ridge_X_t = X_t[results_feature['Ridge']['selected_feature']]\n",
    "ridge_X_te = X_te[results_feature['Ridge']['selected_feature']]\n",
    "\n",
    "ridge_results = evaluate_models_with_test(ridge_model, ridge_X_t, y_t, ridge_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svr_model = models['SVR']\n",
    "svr_X_t = X_t[results_feature['SVR']['selected_feature']]\n",
    "svr_X_te = X_te[results_feature['SVR']['selected_feature']]\n",
    "\n",
    "svr_results = evaluate_models_with_test(svr_model, svr_X_t, y_t, svr_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_model = models['Random Forest']\n",
    "rf_X_t = X_t[results_feature['Random Forest']['selected_feature']]\n",
    "rf_X_te = X_te[results_feature['Random Forest']['selected_feature']]\n",
    "\n",
    "rf_results = evaluate_models_with_test(rf_model, rf_X_t, y_t, rf_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gb_model = models['Gradient Boosting']\n",
    "gb_X_t = X_t[results_feature['Gradient Boosting']['selected_feature']]\n",
    "gb_X_te = X_te[results_feature['Gradient Boosting']['selected_feature']]\n",
    "\n",
    "gb_results = evaluate_models_with_test(gb_model, gb_X_t, y_t, gb_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_model = models['Artificial Neural Network']\n",
    "ann_X_t = X_t[results_feature['Artificial Neural Network']['selected_feature']]\n",
    "ann_X_te = X_te[results_feature['Artificial Neural Network']['selected_feature']]\n",
    "\n",
    "ann_results = evaluate_models_with_test(ann_model, ann_X_t, y_t, ann_X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 20.1076673770882, 'MSE': 902.1385041302448}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 14.695032409248478, 'MSE': 570.2595372331552}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 20.91790633288539, 'MSE': 955.1395825360881}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 23.39522142225316, 'MSE': 1003.343949315722}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 14.532470756135266, 'MSE': 676.9930176271231}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 17.260081814945043, 'MSE': 721.9088243448939}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 22.55849174892375, 'MSE': 1005.3902663530097}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize a list to hold trips\n",
    "# trips = []\n",
    "# current_trip = [df_od_pairs.iloc[0]['origin']]  # Start with the first origin\n",
    "# \n",
    "# # Iterate over the DataFrame rows\n",
    "# for i, row in df_od_pairs.iterrows():\n",
    "#     current_trip.append(row['destination'])  # Always add the destination\n",
    "#     # Check if the next origin matches the current destination\n",
    "#     if i + 1 < len(df_od_pairs) and row['destination'] != df_od_pairs.iloc[i + 1]['origin']:\n",
    "#         # If it doesn't, the current trip has ended\n",
    "#         trips.append(current_trip)\n",
    "#         current_trip = [df_od_pairs.iloc[i + 1]['origin']]  # Start a new trip\n",
    "# \n",
    "# # Add the last trip if it wasn't already added\n",
    "# if current_trip not in trips:\n",
    "#     trips.append(current_trip)\n",
    "\n",
    "\n",
    "# from collections import Counter\n",
    "# # Flatten the list of trips into a single list of nodes including origins and destinations\n",
    "# all_nodes = [node for trip in trips for node in trip]\n",
    "# \n",
    "# # Use Counter to count the occurrences of each node\n",
    "# node_trip_counts = Counter(all_nodes)\n",
    "# \n",
    "# df_node_trip_counts = pd.DataFrame.from_dict(node_trip_counts, orient='index').reset_index()\n",
    "# df_node_trip_counts.columns = ['node_id', 'trip_amount']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
