{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:19:43.963037300Z",
     "start_time": "2024-01-05T00:19:43.928475600Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import expon, reciprocal, uniform\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, DotProduct, ExpSineSquared, RationalQuadratic\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mango import Tuner, scheduler\n",
    "# from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:08:59.821733Z",
     "start_time": "2024-01-05T00:08:33.233652700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file_list, df_activities, df_links_network):\n",
    "    data_frames = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data['link_counts'], dict):\n",
    "                data['link_counts'] = data['link_counts'].values()\n",
    "            df_links = pd.DataFrame({\n",
    "                'link_id': data['links_id'],\n",
    "                'link_from': data['link_from'],\n",
    "                'link_to': data['link_to'],\n",
    "                'link_length': data['link_length'],\n",
    "                'link_freespeed': data['link_freespeed'],\n",
    "                'link_capacity': data['link_capacity'],\n",
    "                'link_permlanes': data['link_permlanes'],\n",
    "                'link_counts': data['link_counts']\n",
    "            })\n",
    "            df_nodes = pd.DataFrame({\n",
    "                'node_id': data['nodes_id'],\n",
    "                'node_x': data['nodes_x'],\n",
    "                'node_y': data['nodes_y']\n",
    "            })\n",
    "            df_od_pairs = pd.DataFrame(data['o_d_pairs'], columns=['origin', 'destination'])\n",
    "            \n",
    "            df_work = pd.DataFrame({\n",
    "                        'work_x': data['work_x'],\n",
    "                        'work_y': data['work_y'],\n",
    "                        'go_to_work': data['go_to_work']\n",
    "            })\n",
    "            df_home = pd.DataFrame({\n",
    "                'home_x': data['home_x'],\n",
    "                'home_y': data['home_y'],\n",
    "                'go_to_home': data['go_to_home']\n",
    "            })\n",
    "            \n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_from', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'start_node_x', 'node_y': 'start_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_nodes, how='left', left_on='link_to', right_on='node_id')\n",
    "            df_links = df_links.rename(columns={'node_x': 'end_node_x', 'node_y': 'end_node_y'})\n",
    "            df_links.drop('node_id', axis=1, inplace=True) \n",
    "            \n",
    "            origin_counts = df_od_pairs['origin'].value_counts()\n",
    "            df_origin_counts = origin_counts.reset_index()\n",
    "            df_origin_counts.columns = ['origin', 'start_count']\n",
    "            destination_counts = df_od_pairs['destination'].value_counts()\n",
    "            df_destination_counts = destination_counts.reset_index()\n",
    "            df_destination_counts.columns = ['destination', 'end_count']\n",
    "            df_links = df_links.merge(df_origin_counts, how='left', left_on='link_from', right_on='origin')\n",
    "            df_links.drop('origin', axis=1, inplace=True)\n",
    "            df_links = df_links.merge(df_destination_counts, how='left', left_on='link_to', right_on='destination')\n",
    "            df_links.drop('destination', axis=1, inplace=True)\n",
    "            df_links[['start_count','end_count']] = df_links[['start_count','end_count']].fillna(-1)\n",
    "            \n",
    "            # Calculate time of go_to_work and go_to_sum\n",
    "            df_act_work = df_activities[df_activities['activity_type_main']=='work'].drop(['end_time'], axis=1)\n",
    "            df_act_work = df_act_work.merge(df_work, how='left', left_on=['x','y'], right_on=['work_x','work_y'])\n",
    "            df_act_work.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_work_agg = df_act_work.groupby(by=\"link\")['go_to_work'].sum().reset_index(drop=False)\n",
    "            df_act_home = df_activities[df_activities['activity_type_main']=='home'].drop(['end_time'], axis=1)\n",
    "            df_act_home = df_act_home.merge(df_home, how='left', left_on=['x','y'], right_on=['home_x','home_y'])\n",
    "            df_act_home.drop(['x','y'], axis=1, inplace=True)\n",
    "            df_act_home_agg = df_act_home.groupby(by=\"link\")['go_to_home'].sum().reset_index(drop=False)\n",
    "            df_act_agg = df_act_home_agg.merge(df_act_work_agg, how='outer', on='link')\n",
    "            df_act_agg.fillna(0, inplace=True)\n",
    "            df_act_agg['go_to_sum'] = df_act_agg['go_to_home'] + df_act_agg['go_to_work']\n",
    "\n",
    "            df_rushhr = df_activities[df_activities['end_time']!=-1]\n",
    "            df_rushhr.loc[:, 'rush_hour'] = 0\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('08:00:00'), pd.to_timedelta('10:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.loc[df_rushhr['end_time'].between(pd.to_timedelta('16:00:00'), pd.to_timedelta('19:00:00'), inclusive='both'), 'rush_hour'] = 1\n",
    "            df_rushhr.drop(['end_time', 'max_dur', 'zoneId', 'cemdapStopDuration_s'], axis=1, inplace=True)\n",
    "            df_rushhragg = df_rushhr.groupby(by=\"link\").sum()['rush_hour'].reset_index(drop=False)\n",
    "            \n",
    "            df_maxduragg = df_activities[df_activities['max_dur']!=-1].groupby(by='link')['max_dur'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_activities['cemdapStopDuration_s'] = df_activities['cemdapStopDuration_s'].astype(float)\n",
    "            df_cemagg = df_activities[df_activities['cemdapStopDuration_s']!=-1].groupby(by='link')['cemdapStopDuration_s'].sum().reset_index(drop=False)\n",
    "            \n",
    "            df_temp = df_links.merge(df_links_network, how='left', on=['start_node_x','start_node_y','end_node_x','end_node_y'])\n",
    "            df_temp = df_temp[['link_id_x','link_from','link_to','link_id_y','from', 'to', 'type']]\n",
    "            df_temp = df_temp.merge(df_act_agg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_rushhragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_maxduragg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.drop('link', axis=1, inplace=True)\n",
    "            df_temp = df_temp.merge(df_cemagg, how='left', left_on='link_id_y', right_on='link')\n",
    "            df_temp.fillna({'cemdapStopDuration_s':-1, 'max_dur':-1, 'rush_hour': -1, 'go_to_sum': -1}, inplace=True)\n",
    "            df_temp = df_temp[['link_id_x', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s', 'type']]\n",
    "            \n",
    "            df_links = df_links.merge(df_temp, how='left', left_on='link_id', right_on='link_id_x')\n",
    "            df_links.drop('link_id_x', axis=1, inplace=True)\n",
    "        data_frames.append(df_links)\n",
    "    return pd.concat(data_frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_files = ['s-0.json', 's-1.json', 's-2.json', 's-3.json', 's-4.json','s-5.json', 's-6.json', 's-7.json', 's-8.json', 's-9.json'] \n",
    "test_files = ['s-15.json', 's-16.json', 's-17.json', 's-18.json','s-19.json']\n",
    "validate_files = ['s-10.json', 's-11.json', 's-12.json', 's-13.json','s-14.json']\n",
    "train_files = ['Data/cutoutWorlds/Train/po-1_pn-1.0_sn-1/' + i for i in train_files]\n",
    "test_files = ['Data/cutoutWorlds/Test/po-1_pn-1.0_sn-1/' + j for j in test_files]\n",
    "validate_files = ['Data/cutoutWorlds/Validate/po-1_pn-1.0_sn-1/' + k for k in validate_files]\n",
    "df_activities = pd.read_pickle(\"Data/cutoutWorlds/Train/po-1_pn-1.0_sn-1/df_activities.pkl\")\n",
    "df_links_network = pd.read_pickle(\"Data/cutoutWorlds/Train/po-1_pn-1.0_sn-1/df_links_network.pkl\")\n",
    "train_data = load_data(train_files, df_activities, df_links_network)\n",
    "test_data = load_data(test_files, df_activities, df_links_network)\n",
    "validate_data = load_data(validate_files, df_activities, df_links_network)\n",
    "Big_train_data = pd.concat([train_data, validate_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:31.053189200Z",
     "start_time": "2024-01-05T00:25:30.986858300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['link_length', 'link_freespeed', 'link_capacity', 'link_permlanes', 'start_node_x', 'start_node_y', 'end_node_x', 'end_node_y', 'start_count', 'end_count', 'go_to_sum', 'rush_hour', 'max_dur', 'cemdapStopDuration_s']\n",
    "category_feature = ['type']\n",
    "X_t = Big_train_data.drop(columns=['link_counts'])\n",
    "y_t = Big_train_data['link_counts']\n",
    "# X_v = validate_data.drop(columns=['link_counts'])\n",
    "# y_v = validate_data['link_counts']\n",
    "X_te = test_data.drop(columns=['link_counts'])\n",
    "y_te = test_data['link_counts']\n",
    "scaler = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ct = ColumnTransformer(\n",
    "     [(\"num_preprocess\", scaler, numerical_features),\n",
    "      (\"text_preprocess\", ohe, category_feature)], remainder='passthrough').set_output(transform=\"pandas\")\n",
    "X_t = ct.fit_transform(X_t)\n",
    "# X_v = ct.fit_transform(X_v)  \n",
    "X_te = ct.fit_transform(X_te)\n",
    "# X_t[numerical_features] = scaler.fit_transform(X_t[numerical_features])\n",
    "# X_v[numerical_features] = scaler.fit_transform(X_v[numerical_features])\n",
    "# X_te[numerical_features] = scaler.fit_transform(X_te[numerical_features])\n",
    "# X_t[category_feature] = le.fit_transform(X_t[category_feature])\n",
    "# X_v[category_feature] = le.fit_transform(X_v[category_feature])\n",
    "# X_te[category_feature] = le.fit_transform(X_te[category_feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:25:38.793260300Z",
     "start_time": "2024-01-05T00:25:38.746926800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': LassoCV(cv=kf, random_state=42, max_iter=100000),\n",
    "    'Ridge': RidgeCV(cv=kf),\n",
    "    'SVR': SVR(C=1, kernel='poly', max_iter=2000),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=650, bootstrap=False, max_depth=19, max_features=0.5, min_samples_leaf=1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(max_depth=18, n_estimators=950, min_samples_split=7, min_samples_leaf=3, max_features=None,\n",
    "                          subsample=0.9, learning_rate=0.01),\n",
    "    'Artificial Neural Network': MLPRegressor(alpha=0.01, max_iter=2000, random_state=42),\n",
    "#     'Gaussian Process Regression': GaussianProcessRegressor(kernel=RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0), alpha=0.1, n_restarts_optimizer=3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T00:31:29.592973900Z",
     "start_time": "2024-01-05T00:28:22.015669500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest selection done\n",
      "Gradient Boosting selection done\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate models\n",
    "def evaluate_models(models, X_train, y_train):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         mse = mean_squared_error(y_test, y_pred)\n",
    "#         mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "        mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "        # Define the cross-validation strategy (e.g., 5-fold cross-validation)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # Perform k-fold cross-validation and calculate MSE and MAE\n",
    "        mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mse_scorer)\n",
    "        mae_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mae_scorer)\n",
    "        # old_mae_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        # Display the mean MSE and MAE across folds\n",
    "        mean_mse = -mse_scores.mean()\n",
    "        mean_mae = -mae_scores.mean()\n",
    "        mean_old_mae = old_mae_scores.mean()\n",
    "        std_mse = mse_scores.std()\n",
    "        # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        # r2 = r2_score(y_test, y_pred)\n",
    "        print(name + \" done\")\n",
    "        \n",
    "        results[name] = {'MAE': mean_mae, 'MSE': mean_mse, 'MSE_std': std_mse, 'MAE_old': mean_old_mae}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def feature_select_models(models, X_train, y_train):\n",
    "    mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name in ['Random Forest', 'Gradient Boosting']:\n",
    "            selector = RFECV(model, step=1, cv=kf, scoring=mae_scorer).fit(X_train, y_train)\n",
    "            print(f'{name} selection done')\n",
    "\n",
    "        # else:\n",
    "        #     # Fit Random Forest to get feature importances\n",
    "        #     rf = RandomForestRegressor()\n",
    "        #     rf.fit(X_train, y_train)\n",
    "        #     # Select features based on importances\n",
    "        #     selector = RFECV(estimator=rf, step=1, cv=kf, scoring=mae_scorer).fit(X_train, y_train)\n",
    "        #     print(f'{name} selection done')\n",
    "            \n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            # X_train_reduced = X_train[selected_features] \n",
    "            # # mse_scores = cross_val_score(model, X_train_reduced, y_train, cv=kf, scoring=mse_scorer)\n",
    "            # # mse = -mse_scores.mean()\n",
    "            # # mse_std = mse_scores.std()           \n",
    "            # mae_scores = cross_val_score(model, X_train_reduced, y_train, cv=kf, scoring=mae_scorer)\n",
    "            # mean_mae = -mae_scores.mean()\n",
    "            mae = selector.cv_results_['mean_test_score']\n",
    "            mae_mean = mae.mean()\n",
    "            results[name] = {'MAE': mae, 'MAE_m': mae_mean, 'selected_feature': selected_features}\n",
    "\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Train and evaluate\n",
    "# results = evaluate_models(models, X_t, y_t)\n",
    "\n",
    "results_feature = feature_select_models(models, X_t, y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 12.425649743866481,\n",
       "  'MSE': 809.9501008981372,\n",
       "  'MSE_std': 140.3128930459079},\n",
       " 'Lasso': {'MAE': 12.838810988648827,\n",
       "  'MSE': 888.6097269093482,\n",
       "  'MSE_std': 165.55719447698084},\n",
       " 'Ridge': {'MAE': 12.397992690840534,\n",
       "  'MSE': 810.8172874182757,\n",
       "  'MSE_std': 142.06562853341467},\n",
       " 'SVR': {'MAE': 18.299609026628282,\n",
       "  'MSE': 1964.7535818311444,\n",
       "  'MSE_std': 302.1950027931552},\n",
       " 'Random Forest': {'MAE': 5.788337364748086,\n",
       "  'MSE': 195.58115266122235,\n",
       "  'MSE_std': 22.496872929381738},\n",
       " 'Gradient Boosting': {'MAE': 8.82080060042972,\n",
       "  'MSE': 389.24053595820317,\n",
       "  'MSE_std': 32.33608498184415},\n",
       " 'Artificial Neural Network': {'MAE': 12.523924398825951,\n",
       "  'MSE': 643.1438894348701,\n",
       "  'MSE_std': 84.2561701392796}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before hyperparametertuning\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 12.425649743866481,\n",
       "  'MSE': 809.9501008981372,\n",
       "  'MSE_std': 140.3128930459079},\n",
       " 'Lasso': {'MAE': 12.838810988648827,\n",
       "  'MSE': 888.6097269093482,\n",
       "  'MSE_std': 165.55719447698084},\n",
       " 'Ridge': {'MAE': 12.397992690840534,\n",
       "  'MSE': 810.8172874182757,\n",
       "  'MSE_std': 142.06562853341467},\n",
       " 'SVR': {'MAE': 23.7828075372924,\n",
       "  'MSE': 1790.0413196154084,\n",
       "  'MSE_std': 283.90271694486614},\n",
       " 'Random Forest': {'MAE': 5.760805324089198,\n",
       "  'MSE': 193.59676221438758,\n",
       "  'MSE_std': 29.37862344359},\n",
       " 'Gradient Boosting': {'MAE': 5.594029310237785,\n",
       "  'MSE': 188.39156397461707,\n",
       "  'MSE_std': 18.52197938284654},\n",
       " 'Artificial Neural Network': {'MAE': 11.45462446420647,\n",
       "  'MSE': 592.0055850205756,\n",
       "  'MSE_std': 77.6416599937703}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after hyperparametertuning\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 12.42564974386646,\n",
       "  'MSE': 809.9501008981365,\n",
       "  'MSE_std': 140.31289304590817,\n",
       "  'MAE_old': -12.42564974386646},\n",
       " 'Lasso': {'MAE': 12.838810988648827,\n",
       "  'MSE': 888.6097269093482,\n",
       "  'MSE_std': 165.55719447698073,\n",
       "  'MAE_old': -12.838810988648827},\n",
       " 'Ridge': {'MAE': 12.397992690840542,\n",
       "  'MSE': 810.8172874182761,\n",
       "  'MSE_std': 142.06562853341413,\n",
       "  'MAE_old': -12.397992690840542},\n",
       " 'SVR': {'MAE': 23.78280753729243,\n",
       "  'MSE': 1790.0413196154095,\n",
       "  'MSE_std': 283.90271694486626,\n",
       "  'MAE_old': -23.78280753729243},\n",
       " 'Random Forest': {'MAE': 5.33024061560253,\n",
       "  'MSE': 167.08464520906492,\n",
       "  'MSE_std': 24.84284389751925,\n",
       "  'MAE_old': -5.337549669326751},\n",
       " 'Gradient Boosting': {'MAE': 5.442269556812587,\n",
       "  'MSE': 192.3176454500369,\n",
       "  'MSE_std': 30.465871274777932,\n",
       "  'MAE_old': -5.459345039893833},\n",
       " 'Artificial Neural Network': {'MAE': 11.45462446420647,\n",
       "  'MSE': 592.0055850205756,\n",
       "  'MSE_std': 77.6416599937703,\n",
       "  'MAE_old': -11.45462446420647}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mae scoring\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('result_cutout_after_featureselection(BO_RFandGB).pkl', 'wb') as file:\n",
    "    pickle.dump(results_feature, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'MAE': array([-17.24378296, -10.0578455 ,  -8.37765443,  -7.27589899,\n",
       "          -6.87809601,  -5.40881245,  -5.39315272,  -5.21071499,\n",
       "          -5.1981582 ,  -5.01832292,  -5.12786941,  -5.20135711,\n",
       "          -5.129635  ,  -5.10685175,  -5.21312153,  -5.32780902,\n",
       "          -5.38397851,  -5.35183649,  -5.33331345,  -5.31253881,\n",
       "          -5.31851434,  -5.32918095,  -5.32892859,  -5.32180508,\n",
       "          -5.32197665,  -5.33021399,  -5.33016062,  -5.32852241,\n",
       "          -5.33510838]),\n",
       "  'MAE_m': -6.086040042778686,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'text_preprocess__type_motorway', 'text_preprocess__type_residential'],\n",
       "        dtype='object')},\n",
       " 'Gradient Boosting': {'MAE': array([-17.29691621, -11.75450656,  -7.99440226,  -5.93899953,\n",
       "          -5.70856085,  -5.62256874,  -5.56182774,  -5.31329082,\n",
       "          -5.25568638,  -5.23438595,  -5.38039294,  -5.53386674,\n",
       "          -5.61567389,  -5.76079657,  -5.66447306,  -5.69186434,\n",
       "          -5.58715045,  -5.51054398,  -5.48586783,  -5.4777184 ,\n",
       "          -5.45776679,  -5.46231734,  -5.45701819,  -5.46014019,\n",
       "          -5.47123546,  -5.46988128,  -5.46318602,  -5.46606624,\n",
       "          -5.4648553 ]),\n",
       "  'MAE_m': -6.226274484257536,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'text_preprocess__type_motorway', 'text_preprocess__type_primary'],\n",
       "        dtype='object')}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BO select feature\n",
    "results_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 12.425649743866481,\n",
       "  'MSE': 809.9501008981372,\n",
       "  'MSE_std': 140.3128930459079,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__go_to_sum', 'num_preprocess__rush_hour',\n",
       "         'num_preprocess__max_dur', 'num_preprocess__cemdapStopDuration_s',\n",
       "         'text_preprocess__type_living_street', 'text_preprocess__type_motorway',\n",
       "         'text_preprocess__type_motorway_link', 'text_preprocess__type_primary',\n",
       "         'text_preprocess__type_primary_link',\n",
       "         'text_preprocess__type_residential', 'text_preprocess__type_secondary',\n",
       "         'text_preprocess__type_secondary_link',\n",
       "         'text_preprocess__type_tertiary', 'text_preprocess__type_trunk',\n",
       "         'text_preprocess__type_trunk_link',\n",
       "         'text_preprocess__type_unclassified', 'remainder__link_id',\n",
       "         'remainder__link_from', 'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'Lasso': {'MAE': 13.068860596495828,\n",
       "  'MSE': 877.1374510015921,\n",
       "  'MSE_std': 161.71064570345098,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__max_dur', 'text_preprocess__type_residential',\n",
       "         'text_preprocess__type_secondary'],\n",
       "        dtype='object')},\n",
       " 'Ridge': {'MAE': 12.397992690840534,\n",
       "  'MSE': 810.8172874182757,\n",
       "  'MSE_std': 142.06562853341467,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__go_to_sum', 'num_preprocess__rush_hour',\n",
       "         'num_preprocess__max_dur', 'num_preprocess__cemdapStopDuration_s',\n",
       "         'text_preprocess__type_living_street', 'text_preprocess__type_motorway',\n",
       "         'text_preprocess__type_motorway_link', 'text_preprocess__type_primary',\n",
       "         'text_preprocess__type_primary_link',\n",
       "         'text_preprocess__type_residential', 'text_preprocess__type_secondary',\n",
       "         'text_preprocess__type_secondary_link',\n",
       "         'text_preprocess__type_tertiary', 'text_preprocess__type_trunk',\n",
       "         'text_preprocess__type_trunk_link',\n",
       "         'text_preprocess__type_unclassified', 'remainder__link_id',\n",
       "         'remainder__link_from', 'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'SVR': {'MAE': 902.346355095621,\n",
       "  'MSE': 855499.4111447213,\n",
       "  'MSE_std': 356467.1505527987,\n",
       "  'selected_feature': Index(['num_preprocess__link_freespeed', 'num_preprocess__link_capacity',\n",
       "         'num_preprocess__link_permlanes', 'num_preprocess__start_node_x',\n",
       "         'num_preprocess__start_node_y', 'num_preprocess__end_node_x',\n",
       "         'num_preprocess__end_node_y', 'text_preprocess__type_motorway'],\n",
       "        dtype='object')},\n",
       " 'Random Forest': {'MAE': 5.244437050829913,\n",
       "  'MSE': 183.45983911456068,\n",
       "  'MSE_std': 42.06489789365005,\n",
       "  'selected_feature': Index(['num_preprocess__link_freespeed', 'num_preprocess__link_capacity',\n",
       "         'num_preprocess__link_permlanes', 'num_preprocess__start_node_x',\n",
       "         'num_preprocess__start_node_y', 'num_preprocess__end_node_x',\n",
       "         'num_preprocess__end_node_y', 'text_preprocess__type_motorway'],\n",
       "        dtype='object')},\n",
       " 'Gradient Boosting': {'MAE': 5.596430454974916,\n",
       "  'MSE': 186.60179717829902,\n",
       "  'MSE_std': 21.739861063704332,\n",
       "  'selected_feature': Index(['num_preprocess__link_length', 'num_preprocess__link_freespeed',\n",
       "         'num_preprocess__link_capacity', 'num_preprocess__link_permlanes',\n",
       "         'num_preprocess__start_node_x', 'num_preprocess__start_node_y',\n",
       "         'num_preprocess__end_node_x', 'num_preprocess__end_node_y',\n",
       "         'num_preprocess__start_count', 'num_preprocess__end_count',\n",
       "         'num_preprocess__max_dur', 'num_preprocess__cemdapStopDuration_s',\n",
       "         'text_preprocess__type_motorway', 'text_preprocess__type_motorway_link',\n",
       "         'text_preprocess__type_primary', 'text_preprocess__type_residential',\n",
       "         'text_preprocess__type_secondary', 'text_preprocess__type_tertiary',\n",
       "         'remainder__link_id', 'remainder__link_from', 'remainder__link_to'],\n",
       "        dtype='object')},\n",
       " 'Artificial Neural Network': {'MAE': 10.829817473570653,\n",
       "  'MSE': 470.8458014222315,\n",
       "  'MSE_std': 15.039272176600944,\n",
       "  'selected_feature': Index(['num_preprocess__link_freespeed', 'num_preprocess__link_capacity',\n",
       "         'num_preprocess__link_permlanes', 'num_preprocess__start_node_x',\n",
       "         'num_preprocess__start_node_y', 'num_preprocess__end_node_x',\n",
       "         'num_preprocess__end_node_y', 'text_preprocess__type_motorway'],\n",
       "        dtype='object')}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T15:58:29.829296Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07439e8958914ebca626a3f11816ef54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mresult\n\u001b[0;32m     18\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(param_space, objective)\n\u001b[1;32m---> 19\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_objective\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:156\u001b[0m, in \u001b[0;36mTuner.maximize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaximize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:147\u001b[0m, in \u001b[0;36mTuner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_bayesian:\n\u001b[1;32m--> 147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunBayesianOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_random:\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunRandomOptimizer()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:274\u001b[0m, in \u001b[0;36mTuner.runBayesianOptimizer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m     X_next_PS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mget_random_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# Evaluate the Objective function\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m X_next_list, Y_next_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunUserObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next_PS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# keep track of all parameters that failed\u001b[39;00m\n\u001b[0;32m    277\u001b[0m x_failed \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_next_PS \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m X_next_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:374\u001b[0m, in \u001b[0;36mTuner.runUserObjective\u001b[1;34m(self, X_next_PS)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunUserObjective\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_next_PS):\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# initially assuming entire X_next_PS is evaluated and returned results are only Y values\u001b[39;00m\n\u001b[0;32m    373\u001b[0m     X_list_evaluated \u001b[38;5;241m=\u001b[39m X_next_PS\n\u001b[1;32m--> 374\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next_PS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m     Y_list_evaluated \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# if result is a tuple, then there is possibility that partial values are evaluated\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\scheduler.py:30\u001b[0m, in \u001b[0;36mparallel.<locals>.decorator.<locals>.wrapper\u001b[1;34m(params_batch)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(params_batch):\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_space = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100],  # Extended range for the regularization parameter\n",
    "    gamma=['scale', 'auto'],  # Including specific gamma values\n",
    "    kernel=['linear', 'poly', 'rbf', 'sigmoid'],  # Focusing on RBF kernel\n",
    "    epsilon=[0.01, 0.1, 0.2],  # Epsilon in the epsilon-SVR model\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**hyper_par):\n",
    "    global X_t, y_t\n",
    "    clf = SVR(**hyper_par)\n",
    "    result = cross_val_score(clf, X_t, y_t, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1).mean()\n",
    "    return -result\n",
    "\n",
    "\n",
    "tuner = Tuner(param_space, objective)\n",
    "results = tuner.maximize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T01:20:56.486270700Z",
     "start_time": "2023-12-31T01:19:49.061059700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30519cedc6524ba7bba57a6efd426231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'bootstrap': False, 'max_depth': 19, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 650}\n",
      "best accuracy: -5.32645951137565\n"
     ]
    }
   ],
   "source": [
    "param_space =  dict(\n",
    "    max_features=['sqrt', 'log2', .1, .3, .5, .7, .9],\n",
    "    n_estimators=range(50, 1001, 50), # 10 to 1000 in steps of 50\n",
    "    bootstrap=[True, False],\n",
    "    max_depth=range(1, 20),\n",
    "    min_samples_leaf=range(1, 10)\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**hyper_par):\n",
    "    global X_t, y_t\n",
    "\n",
    "    clf = RandomForestRegressor(**hyper_par)\n",
    "    result = cross_val_score(clf, X_t, y_t, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1).mean()\n",
    "    return result\n",
    "\n",
    "\n",
    "tuner = Tuner(param_space, objective)\n",
    "results = tuner.maximize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T14:55:59.094098400Z",
     "start_time": "2023-12-31T14:48:54.215646500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dc9e9704064e758e1fadfd8fdd08fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.01, 'max_depth': 18, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 950, 'subsample': 0.9}\n",
      "best accuracy: -5.4671055208492945\n"
     ]
    }
   ],
   "source": [
    "param_space = dict(\n",
    "    n_estimators=range(50, 1001, 50),\n",
    "    learning_rate=[0.001, 0.01, 0.1, 0.2, 0.3],  # Varied learning rates for gradient boosting\n",
    "    max_depth=range(1, 20),\n",
    "    min_samples_split=range(2, 11, 1),\n",
    "    min_samples_leaf=range(1, 10),\n",
    "    subsample= [0.8, 0.9, 1.0],  # Fraction of samples to be used for fitting individual base learners\n",
    "    max_features=['sqrt', 'log2', None]\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**hyper_par):\n",
    "    global X_t, y_t\n",
    "\n",
    "    clf = GradientBoostingRegressor(**hyper_par)\n",
    "    result = cross_val_score(clf, X_t, y_t, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1).mean()\n",
    "    return result\n",
    "\n",
    "tuner = Tuner(param_space, objective)\n",
    "results = tuner.maximize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T19:56:11.590867600Z",
     "start_time": "2024-01-02T19:50:33.301610200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e279278b2b954d7799a947a42c67cf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n    raise ValueError(\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5756\\4212819552.py\", line 16, in objective\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n    cv_results = cross_validate(\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 214, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 328, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 414, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n    raise ValueError(\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m     19\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(param_space, objective)\n\u001b[1;32m---> 20\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_objective\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:156\u001b[0m, in \u001b[0;36mTuner.maximize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaximize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:147\u001b[0m, in \u001b[0;36mTuner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_bayesian:\n\u001b[1;32m--> 147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunBayesianOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_random:\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunRandomOptimizer()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:274\u001b[0m, in \u001b[0;36mTuner.runBayesianOptimizer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m     X_next_PS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mget_random_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# Evaluate the Objective function\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m X_next_list, Y_next_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunUserObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next_PS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# keep track of all parameters that failed\u001b[39;00m\n\u001b[0;32m    277\u001b[0m x_failed \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_next_PS \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m X_next_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\tuner.py:374\u001b[0m, in \u001b[0;36mTuner.runUserObjective\u001b[1;34m(self, X_next_PS)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunUserObjective\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_next_PS):\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# initially assuming entire X_next_PS is evaluated and returned results are only Y values\u001b[39;00m\n\u001b[0;32m    373\u001b[0m     X_list_evaluated \u001b[38;5;241m=\u001b[39m X_next_PS\n\u001b[1;32m--> 374\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next_PS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m     Y_list_evaluated \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# if result is a tuple, then there is possibility that partial values are evaluated\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mango\\scheduler.py:30\u001b[0m, in \u001b[0;36mparallel.<locals>.decorator.<locals>.wrapper\u001b[1;34m(params_batch)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(params_batch):\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n    raise ValueError(\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n"
     ]
    }
   ],
   "source": [
    "param_space = dict(\n",
    "    hidden_layer_sizes=[(50,), (100,), (50, 50), (100, 100), (30, 30, 30)],\n",
    "    activation= ['tanh', 'relu', 'identity', 'logistic'],\n",
    "    solver= ['sgd', 'adam'],\n",
    "    alpha= [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    max_iter=range(1000, 5001, 1000)\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**hyper_par):\n",
    "    global X_t, y_t\n",
    "\n",
    "    clf = MLPRegressor(**hyper_par)\n",
    "    result = cross_val_score(clf, X_t, y_t, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1).mean()\n",
    "    return result\n",
    "\n",
    "tuner = Tuner(param_space, objective)\n",
    "results = tuner.maximize()\n",
    "print('best parameters:', results['best_params'])\n",
    "print('best accuracy:', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T21:55:20.525741600Z",
     "start_time": "2024-01-01T20:54:36.357249300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15896\\1928377076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Initialize GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgrid_search_gpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrid_search_gpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search_gpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m         \u001b[0mcv_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2305\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2307\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    287\u001b[0m                 \u001b[1;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[1;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0."
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, DotProduct\n",
    "import numpy as np\n",
    "param_grid = {\n",
    "    'kernel': [ConstantKernel (1.0, (1e-1, 1e1)) * RBF(1.0, (1e-2, 1e2))],\n",
    "    'alpha': [ 1e-2, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "gpr = GaussianProcessRegressor(copy_X_train=False)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_gpr = RandomizedSearchCV(gpr, param_grid, n_iter=5, cv=0, scoring='neg_mean_squared_error', n_jobs=-1, verbose=10)\n",
    "grid_search_gpr.fit(X_t, y_t)\n",
    "\n",
    "print(grid_search_gpr.best_params_)\n",
    "print(grid_search_gpr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models_with_test(model, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "      \n",
    "    results = {'MAE': mae, 'MSE': mse}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "result_final_with_test = {}\n",
    "for name, model in models.items():\n",
    "    if name in ['Random Forest', 'Gradient Boosting']:\n",
    "        X_t_reduced = X_t[results_feature[name]['selected_feature']]\n",
    "        X_te_reduced = X_te[results_feature[name]['selected_feature']]\n",
    "        result_final_with_test[name] = evaluate_models_with_test(model, X_t_reduced, y_t, X_te_reduced, y_te)\n",
    "    # else:\n",
    "    # result_final_with_test[name] = evaluate_models_with_test(model, X_t, y_t, X_te, y_te)\n",
    "\n",
    "# with open('result_cutout_final(wo gpr).pkl', 'wb') as file:\n",
    "#     pickle.dump(result_final_with_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'MAE': 15.408751754177185, 'MSE': 616.0415054078707},\n",
       " 'Gradient Boosting': {'MAE': 17.594169844517467, 'MSE': 906.6786634713227}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BO w/ feature\n",
    "result_final_with_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 20.174646411039785, 'MSE': 907.5637017883494},\n",
       " 'Lasso': {'MAE': 15.94555308382198, 'MSE': 623.346131490013},\n",
       " 'Ridge': {'MAE': 20.15102515583173, 'MSE': 899.627760582678},\n",
       " 'SVR': {'MAE': 24.28971478267384, 'MSE': 1022.310088408284},\n",
       " 'Random Forest': {'MAE': 13.544514569822395, 'MSE': 540.7677890007706},\n",
       " 'Gradient Boosting': {'MAE': 14.415849761332476, 'MSE': 720.1563227840516},\n",
       " 'Artificial Neural Network': {'MAE': 51.41355254068389,\n",
       "  'MSE': 10314.245120300402}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BO w/o feature\n",
    "result_final_with_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 20.17464641103979, 'MSE': 907.5637017883504},\n",
       " 'Lasso': {'MAE': 19.630499926649197, 'MSE': 827.446194872528},\n",
       " 'Ridge': {'MAE': 20.15102515583173, 'MSE': 899.627760582678},\n",
       " 'SVR': {'MAE': 24.289714782673844, 'MSE': 1022.3100884082841},\n",
       " 'Random Forest': {'MAE': 19.925688067490935, 'MSE': 860.415125118749},\n",
       " 'Gradient Boosting': {'MAE': 14.206169892700725, 'MSE': 653.6444558714534},\n",
       " 'Artificial Neural Network': {'MAE': 29.089758158721573,\n",
       "  'MSE': 1716.4521812762798}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final_with_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'MAE': 20.17464641103979, 'MSE': 907.5637017883504},\n",
       " 'Lasso': {'MAE': 19.630499926649197, 'MSE': 827.446194872528},\n",
       " 'Ridge': {'MAE': 20.15102515583173, 'MSE': 899.627760582678},\n",
       " 'SVR': {'MAE': 622.6378771377161, 'MSE': 389044.89117324405},\n",
       " 'Random Forest': {'MAE': 19.925688067490935, 'MSE': 860.415125118749},\n",
       " 'Gradient Boosting': {'MAE': 14.206169892700725, 'MSE': 653.6444558714534},\n",
       " 'Artificial Neural Network': {'MAE': 29.089758158721573,\n",
       "  'MSE': 1716.4521812762798}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR with feature selection\n",
    "result_final_with_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 20.1076673770882, 'MSE': 902.1385041302448}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 14.695032409248478, 'MSE': 570.2595372331552}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 20.91790633288539, 'MSE': 955.1395825360881}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 23.39522142225316, 'MSE': 1003.343949315722}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 14.532470756135266, 'MSE': 676.9930176271231}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 17.260081814945043, 'MSE': 721.9088243448939}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 22.55849174892375, 'MSE': 1005.3902663530097}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize a list to hold trips\n",
    "# trips = []\n",
    "# current_trip = [df_od_pairs.iloc[0]['origin']]  # Start with the first origin\n",
    "# \n",
    "# # Iterate over the DataFrame rows\n",
    "# for i, row in df_od_pairs.iterrows():\n",
    "#     current_trip.append(row['destination'])  # Always add the destination\n",
    "#     # Check if the next origin matches the current destination\n",
    "#     if i + 1 < len(df_od_pairs) and row['destination'] != df_od_pairs.iloc[i + 1]['origin']:\n",
    "#         # If it doesn't, the current trip has ended\n",
    "#         trips.append(current_trip)\n",
    "#         current_trip = [df_od_pairs.iloc[i + 1]['origin']]  # Start a new trip\n",
    "# \n",
    "# # Add the last trip if it wasn't already added\n",
    "# if current_trip not in trips:\n",
    "#     trips.append(current_trip)\n",
    "\n",
    "\n",
    "# from collections import Counter\n",
    "# # Flatten the list of trips into a single list of nodes including origins and destinations\n",
    "# all_nodes = [node for trip in trips for node in trip]\n",
    "# \n",
    "# # Use Counter to count the occurrences of each node\n",
    "# node_trip_counts = Counter(all_nodes)\n",
    "# \n",
    "# df_node_trip_counts = pd.DataFrame.from_dict(node_trip_counts, orient='index').reset_index()\n",
    "# df_node_trip_counts.columns = ['node_id', 'trip_amount']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
